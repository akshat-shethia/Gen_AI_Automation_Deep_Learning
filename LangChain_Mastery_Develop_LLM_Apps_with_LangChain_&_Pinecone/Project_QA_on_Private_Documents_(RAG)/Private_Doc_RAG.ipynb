{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading PDF, DOCX and TXT files as LangChain Documents\n",
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file) # Splitting the Name and Extension\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "The\n",
      "House\n",
      "of\n",
      "Representatives\n",
      "shall\n",
      "be\n",
      "composed\n",
      "of\n",
      "Members\n",
      "chosen\n",
      "every\n",
      "second\n",
      "Y ear\n",
      "by\n",
      "the\n",
      "People\n",
      "of\n",
      "the\n",
      "several\n",
      "States,\n",
      "and\n",
      "the\n",
      "Electors\n",
      "in\n",
      "each\n",
      "State\n",
      "shall\n",
      "have\n",
      "the\n",
      "Qualifications\n",
      "requisite\n",
      "for\n",
      "Electors\n",
      "of\n",
      "the\n",
      "most\n",
      "numerous\n",
      "Branch\n",
      "of\n",
      "the\n",
      "State\n",
      "Legislature.\n",
      "No\n",
      "Person\n",
      "shall\n",
      "be\n",
      "a\n",
      "Representative\n",
      "who\n",
      "shall\n",
      "not\n",
      "have\n",
      "attained\n",
      "to\n",
      "the\n",
      "Age\n",
      "of\n",
      "twenty\n",
      "five\n",
      "Y ears,\n",
      "and\n",
      "been\n",
      "seven\n",
      "Y ears\n",
      "a\n",
      "Citizen\n",
      "of\n",
      "the\n",
      "United\n",
      "States,\n",
      "and\n",
      "who\n",
      "shall\n",
      "not,\n",
      "when\n",
      "elected,\n",
      "be\n",
      "an\n",
      "Inhabitant\n",
      "of\n",
      "that\n",
      "State\n",
      "in\n",
      "which\n",
      "he\n",
      "shall\n",
      "be\n",
      "chosen.\n",
      "Representatives\n",
      "and\n",
      "direct\n",
      "T axes\n",
      "shall\n",
      "be\n",
      "apportioned\n",
      "among\n",
      "the\n",
      "several\n",
      "States\n",
      "which\n",
      "may\n",
      "be\n",
      "included\n",
      "within\n",
      "this\n",
      "Union,\n",
      "according\n",
      "to\n",
      "their\n",
      "respective\n",
      "Numbers,\n",
      "which\n",
      "shall\n",
      "be\n",
      "determined\n",
      "by\n",
      "adding\n",
      "to\n",
      "the\n",
      "whole\n",
      "Number\n",
      "of\n",
      "free\n",
      "Persons,\n",
      "including\n",
      "those\n",
      "bound\n",
      "to\n",
      "Service\n",
      "for\n",
      "a\n",
      "T erm\n",
      "of\n",
      "Y ears,\n",
      "and\n",
      "excluding\n",
      "Indians\n",
      "not\n",
      "taxed,\n",
      "three\n",
      "fifths\n",
      "of\n",
      "all\n",
      "other\n",
      "Persons.\n",
      "The\n",
      "actual\n",
      "Enumeration\n",
      "shall\n",
      "be\n",
      "made\n",
      "within\n",
      "three\n",
      "Y ears\n",
      "after\n",
      "the\n",
      "first\n",
      "Meeting\n",
      "of\n",
      "the\n",
      "Congress\n",
      "of\n",
      "the\n",
      "United\n",
      "States,\n",
      "and\n",
      "within\n",
      "every\n",
      "subsequent\n",
      "T erm\n",
      "of\n",
      "ten\n",
      "Y ears,\n",
      "in\n",
      "such\n",
      "Manner\n",
      "as\n",
      "they\n",
      "shall\n",
      "by\n",
      "Law\n",
      "direct.The\n",
      "number\n",
      "of\n",
      "Representatives\n",
      "shall\n",
      "not\n",
      "exceed\n",
      "one\n",
      "for\n",
      "every\n",
      "thirty\n",
      "Thousand,\n",
      "but\n",
      "each\n",
      "State\n",
      "shall\n",
      "have\n",
      "at\n",
      "Least\n",
      "one\n",
      "Representative;\n",
      "and\n",
      "until\n",
      "such\n",
      "enumeration\n",
      "shall\n",
      "be\n",
      "made,\n",
      "the\n",
      "State\n",
      "of\n",
      "New\n",
      "Hampshire\n",
      "shall\n",
      "be\n",
      "entitled\n",
      "to\n",
      "chuse\n",
      "three,\n",
      "Massachusetts\n",
      "eight,\n",
      "Rhode-Island\n",
      "and\n",
      "Providence\n",
      "Plantations\n",
      "one,\n",
      "Connecticut\n",
      "five,\n",
      "New-Y ork\n",
      "six,\n",
      "New\n",
      "Jersey\n",
      "four ,\n",
      "Pennsylvania\n",
      "eight,\n",
      "Delaware\n",
      "one,\n"
     ]
    }
   ],
   "source": [
    "data = load_document(\"files/us_constitution.pdf\")\n",
    "print(data[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.: 2 \n",
      "Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.\n",
      "\n",
      "\n",
      "== Background ==\n",
      " \n",
      "\n",
      "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with over 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
      "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
      "\n",
      "\n",
      "== Capabilities ==\n",
      "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams. It can now interact with users through spoken words and respond to images, allowing for more natural conversations and the ability to provide suggestions or answers based on photo uploads.\n",
      "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n",
      "When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n",
      "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing\n"
     ]
    }
   ],
   "source": [
    "data = load_from_wikipedia(\"GPT-4\")\n",
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "You have 41 pages in your data\n",
      "There are 1137 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/us_constitution.pdf')\n",
    "# print(data[1].page_content)\n",
    "# print(data[10].metadata)\n",
    "\n",
    "print(f'You have {len(data)} pages in your data')\n",
    "print(f'There are {len(data[20].page_content)} characters in the page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    # check prices here: https://openai.com/pricing\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.00002:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    # importing the necessary libraries and initializing the Pinecone client\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import ServerlessSpec\n",
    "\n",
    "    \n",
    "    pc = pinecone.Pinecone()\n",
    "        \n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)  # 512 works as well\n",
    "\n",
    "    # loading from existing index\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        # creating the index and embedding the chunks into the index \n",
    "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
    "\n",
    "        # creating a new index\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "        ) \n",
    "        )\n",
    "\n",
    "        # processing the input documents, generating embeddings using the provided `OpenAIEmbeddings` instance,\n",
    "        # inserting the embeddings into the index and returning a new Pinecone vector store object. \n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "        \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pc = pinecone.Pinecone()\n",
    "    \n",
    "    if index_name == 'all':\n",
    "        indexes = pc.list_indexes().names()\n",
    "        print('Deleting all indexes ... ')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pc.delete_index(index_name)\n",
    "        print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "# print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 16711\n",
      "Embedding Cost in USD: 0.000334\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q IProgress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = 'askadocument'\n",
    "vector_store = insert_or_fetch_embeddings(index_name=index_name, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASKING AND GETTING ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini', temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.invoke(q)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text provided is excerpts from the United States Constitution. The Constitution outlines the framework for the government of the United States, establishing the branches of government, their powers, and the rights of the citizens. It serves as the supreme law of the United States.\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the whole document about?\"\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## While Loop For Asking Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit.\n",
      "\n",
      "Answer: The First Amendment of the United States Constitution guarantees the freedom of religion, speech, press, assembly, and the right to petition the government.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "\n",
      "Answer: The concept of federalism as mentioned in the Constitution refers to the division of power between the central government and the individual states. It establishes a system where both levels of government have their own distinct powers and responsibilities. This division of power is intended to create a balance between a strong central authority and individual state autonomy. The Constitution outlines specific powers granted to the federal government, powers reserved for the states, and powers shared between the two levels of government. This framework of federalism ensures that no single entity has unchecked power and helps maintain a system of checks and balances in the United States government.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "\n",
      "Answer: The Bill of Rights is the first ten amendments to the United States Constitution. It guarantees specific rights and freedoms to the people, such as freedom of speech, religion, and the press, the right to bear arms, protection against unreasonable search and seizure, the right to a fair and speedy trial, and limitations on government power in regards to the rights of individuals.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Quitting ... bye bye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "print('Write Quit or Exit to quit.')\n",
    "while True:\n",
    "    q = input(f'Question #{i}: ')\n",
    "    i = i + 1\n",
    "    if q.lower() in ['quit', 'exit']:\n",
    "        print('Quitting ... bye bye!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f'\\nAnswer: {answer['result']}')\n",
    "    print(f'\\n {\"-\" * 50} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='== Funktionsweise =='),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Ähnlich wie OpenAIs Konkurrenzprodukt ChatGPT kann Google Gemini in einer gesprächsähnlichen Art eine Vielzahl von Fragen beantworten. Gemini erlaubt multimodales Arbeiten, das heißt, man kann sowohl diverse Medien wie Sprache oder Fotos eingeben als auch'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='unterschiedliche Formate, wie Code oder Sprache, ausgegeben bekommen. Allerdings ist Gemini aktuell (Stand Februar 2024), anders als ChatGPT, nicht in der Lage, selbst Bilder zu erstellen – obwohl Google diese Funktion seit Längerem in Aussicht gestellt'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='hat.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Der Chatbot wurde zunächst auf Basis von LaMDA, einem Large Language Model (LLM), entwickelt, bevor er ab Mai 2023 auf das bessere Modell PaLM 2 und seit Dezember 2023 auf das neu entwickelte gleichnamige LLM Gemini Pro 1.5 zurückgreift.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini Pro 1.5 basiert auf der Transformer-Architektur mit einem stark erweiterten Kontexterfassungsfenster und mehreren parallelen „Experten“-Neuronalen-Netzwerken.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Die auf Gemini basierende Version ist mit Stand Februar 2024 in mehr als 230 Ländern und Regionen und in 40 Sprachen verfügbar.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Anders als ChatGPT 4 ist die Nutzung von Google Gemini kostenlos, jedoch gibt es auch eine kostenpflichtige Version namens Gemini Advanced. Allerdings weist Google selbst darauf hin, dass das Tool noch Schwächen habe. Google bezeichnete Bard zu Beginn der'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Veröffentlichung selbst als Experiment, ehe es mit dem Rebranding als Gemini nunmehr kein Experiment ist.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='== Gemini-Varianten ==\\nGemini wird in den Stufen Nano, Pro und Ultra angeboten:'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini Nano wird mit optimiertem Speicherbedarf lokal auf Samsung Galaxy S24- oder Pixel-Smartphones benutzt.\\nGemini Pro (einst Bard) ist die Standardversion.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini Ultra dient der Lösung komplexer Aufgaben. Es steht mit Gemini Advanced für Privatnutzer im ChatBot und in Workspace-Apps bereit – oder im Workspace Business-Paket.Gemini Advanced umfasst kostenpflichtige Versionen (statt Gemini Pro). Diese'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Ultra-Version gibt es nur mit Google One AI Premium.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Google One AI Premium ist ein Abo-Paket für Google One. Google One selbst dient nur der Abrechnung. Für US-Nutzer kann der Google One-Zugang zu Gemini Advanced geteilt werden.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini für Google Workspace ist die Business-Version als Gemini-Integration in GMail, Docs, Sheets und Google Meet. Es ist Oberbegriff für Ultra-Merkmale in Workspace mit den Tarifen Business oder Enterprise.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini Business ist das auf Google Workspace aufbauende Abo für Gemini in Workspace-Apps für 20 Dollar im Monat pro Nutzer – analog zu Advanced oder Google One AI Premium.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini Enterprise als leistungsfähigere Variante von Gemini Business kostet 30 Dollar im Monat pro Nutzer.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Die Gemini Android-App ist für US-Nutzer nutzbar sowie per APK-Sideload weltweit. Die App kann den Google Assistant ablösen, der in reduzierter Nützlichkeit als Plug-In integriert ist. Gemini für Android entspricht Gemini im Web. Seit Juni 2024 ist die'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Gemini App auch in Deutscher Sprache verfügbar.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Googles Open-Source-Projekt Gemma nutzt Gemini-Technologie und steht Entwicklern und Nutzern offen.'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='== Geschichte =='),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Auf einer Konferenz bezeichneten Google-Manager Anfang 2023 ChatGPT als „Code Red“ (also ein klares Warnsignal an Google), da die AI-basierte Plattform des Konkurrenten eine unerwartet positive Resonanz von Nutzern auf der ganzen Welt erhalten hätte. In'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='einem Blog-Beitrag gab Google bekannt, dass es sein eigenes Produkt unter der Marke Bard „vertrauenswürdigen Testern“ zur Verfügung stellen werde, bevor es für die Öffentlichkeit zugänglich gemacht werde. Der Chatbot von Google war nach William'),\n",
       " Document(metadata={'title': 'Google Gemini', 'summary': 'Google Gemini (ehemals Google Bard) ist ein von Google entwickelter KI-basierter, multimodaler Chatbot. Er wurde als direkte Reaktion auf den Erfolg von ChatGPT entwickelt und im März 2023 in eingeschränkter Kapazität veröffentlicht, bevor er im Laufe des Sommers in weiteren Ländern verfügbar wurde. Google Gemini ist in über 40 Sprachen verfügbar.', 'source': 'https://de.wikipedia.org/wiki/Google_Gemini'}, page_content='Shakespeare benannt, der auch als „Bard of Avon“ (auf Deutsch: „Dichter von Avon“) bezeichn'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='== Abgrenzung der Gemini-Versionen ==\\nGemini ist ein Produktname, der das KI-Modell wie auch den Chatbot meint und zur übergreifenden Bezeichnung geworden ist. Das KI-Modell wird in den Stufen Gemini Nano, Gemini Pro und Gemini Ultra angeboten:'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Gemini Nano ist ein bezüglich Speicherbedarf optimiertes schlankes Sprachmodell für Smartphones wie Pixel 8 oder Samsung Galaxy S24.\\nGemini Pro deckt als Standardversion ein breites Aufgabenspektrum ab.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Gemini Ultra soll hochkomplexe Aufgaben multimodaler Art (Text- und Medienverarbeitung) lösen. Gemini Ultra steht mit Gemini Advanced für Privatnutzer sowohl im KI-Chatbot als auch in Workspace-Apps zur Verfügung. Auch ist es im Workspace-Business-Paket'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='nutzbar.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Gemini ist auch der Name des Google-Chatbots. Dieser hieß zuvor Bard, Google nannte ihn aber im Februar 2024 um. Die Basisversion von Gemini ist kostenlos, das leistungsfähigere Gemini Advanced kostenpflichtig und nur über Google One AI Premium zu buchen.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Bei Google One AI Premium ist ein Abo-Paket für Google One mit mindestens 2 TByte Speicher sowie Gemini Advanced erhältlich.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Weitere Produkte sind „Gemini für Google Workspace“ als Business-Version, die auch als „Duet AI“ angeboten wurde und zusätzlich zu Workspace-Paketen nutzbar ist. Es bietet die Gemini-Integration in GMail, Docs, Sheets, Google Meet. Es ist der neue'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Oberbegriff für die auf Gemini Ultra basierenden Gemini-Features in Workspace, die sich freischalten lassen für die Tarife „Gemini Business“ oder „Gemini Enterprise“: Gemini Business ist das auf Google Workspace aufbauende Abo für Gemini-Funktionen in den'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Workspace-Apps für derzeit 19 Euro pro Monat pro Nutzer. Es ist das Business-Pendant zu Gemini Advanced bzw. Google One AI Premium. Gemini Enterprise ist die leistungsfähigere Gemini-Business-Variante: Zusätzlich sind unter anderem'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Untertitel-Übersetzungen enthalten. Gemini Enterprise 29 Euro pro Monat und Nutzer.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Die Gemini-Android-App ist über einen Gemini APK-Sideload auch in Deutschland nutzbar. Die App kann den Google Assistant unter Android ablösen, der als Plug-in in die App integriert ist. Gemini für Android entspricht Gemini im Web, bietet aber mit der'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Assistant-Infrastruktur mehr Möglichkeiten.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Auch das Open-Source-Projekt Gemma basiert auf Gemini-Technik und steht Entwicklern und interessierten Nutzern offen.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='== Kritik ==\\nNach der Vorstellung von Gemini im Dezember 2023 wurde Kritik an Google geäußert, weil Demovideos offenbar deutlich bearbeitet wurden, um Gemini leistungsfähiger erscheinen zu lassen.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='== Trivia =='),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='Der Name Gemini steht im Lateinischen für das Sternbild Zwillinge und hier für die Partnerschaft der beiden großen KI-Labore von Google, Google DeepMind und Google Brain, und ist zudem eine Anspielung auf das NASA-Projekt Gemini, das in den 60er-Jahren'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='den Weg für die Mondlandungen des späteren Apollo-Programms ebnete.'),\n",
       " Document(metadata={'title': 'Gemini (Sprachmodell)', 'summary': 'Gemini ist eine Serie multimodaler Sprachmodelle des US-amerikanischen Unternehmens Google. Sie zählt zum Bereich Generativer Künstlicher Intelligenz (GenAI). Entwickelt wurde es von Googles Tochterunternehmen DeepMind und baut auf den zuvor bereits von Google herausgebrachten Sprachmodellen LaMDA und PaLM auf. Gemini wurde im Dezember 2023 angekündigt und wird von vielen Marktbeobachtern als Konkurrent zu GPT-4 von OpenAI gesehen.', 'source': 'https://de.wikipedia.org/wiki/Gemini_(Sprachmodell)'}, page_content='== Weblinks ==\\nOffizielle Website\\nGemini: A Family of Highly Capable Multimodal Models White Paper (PDF, 62 Seiten, englisch)\\n\\n\\n== Einzelnachweise ==')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_from_wikipedia('Google Gemini', 'de')\n",
    "chunks = chunk_data(data)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index gemini and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = 'gemini'\n",
    "vector_store = insert_or_fetch_embeddings(index_name=index_name, chunks=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Gemini ist ein KI-basierter, multimodaler Chatbot, der von Google entwickelt wurde. Er war zuvor unter dem Namen Google Bard bekannt. Gemini bietet eine kostenlose Basisversion an, während eine leistungsfähigere Version namens Gemini Advanced kostenpflichtig ist und nur über Google One AI Premium zu buchen ist.\n"
     ]
    }
   ],
   "source": [
    "q = 'Was ist Google Gemini?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Chroma as a Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_chroma(chunks, persist_directory='./chroma_db'):\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    # Instantiate an embedding model from OpenAI (smaller version for efficiency)\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)  \n",
    "\n",
    "    # Create a Chroma vector store using the provided text chunks and embedding model, \n",
    "    # configuring it to save data to the specified directory \n",
    "    vector_store = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory) \n",
    "\n",
    "    return vector_store  # Return the created vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_chroma(persist_directory='./chroma_db'):\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    # Instantiate the same embedding model used during creation\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536) \n",
    "\n",
    "    # Load a Chroma vector store from the specified directory, using the provided embedding function\n",
    "    vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings) \n",
    "\n",
    "    return vector_store  # Return the loaded vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/rag_powered_by_google_search.pdf\n"
     ]
    }
   ],
   "source": [
    "data = load_document(\"files/rag_powered_by_google_search.pdf\")\n",
    "chunks = chunk_data(data, chunk_size = 256)\n",
    "vector_store = create_embeddings_chroma(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI Search is a feature that offers customizable answers, search tuning, vector search, grounding, and compliance updates for enterprises. It provides generative AI capabilities and enterprise-ready features for improved search experiences.\n"
     ]
    }
   ],
   "source": [
    "# Asking questions\n",
    "q = 'What is Vertex AI Search?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain  # Import class for building conversational AI chains \n",
    "from langchain.memory import ConversationBufferMemory  # Import memory for storing conversation history\n",
    "\n",
    "# Instantiate a ChatGPT LLM (temperature controls randomness)\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)  \n",
    "\n",
    "# Configure vector store to act as a retriever (finding similar items, returning top 5)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 5})  \n",
    "\n",
    "\n",
    "# Create a memory buffer to track the conversation\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,  # Link the ChatGPT LLM\n",
    "    retriever=retriever,  # Link the vector store based retriever\n",
    "    memory=memory,  # Link the conversation memory\n",
    "    chain_type='stuff',  # Specify the chain type\n",
    "    verbose=False  # Set to True to enable verbose logging for debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to ask questions\n",
    "def ask_question(q, chain):\n",
    "    result = chain.invoke({'question': q})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Stack Overflow dataset had 8 million pairs of questions and answers.\n"
     ]
    }
   ],
   "source": [
    "q = 'How many pairs of questions and answers had the StackOverflow dataset?'\n",
    "result = ask_question(q, crc)\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Multiply that number by 10.', 'chat_history': [HumanMessage(content='How many pairs of questions and answers had the StackOverflow dataset?'), AIMessage(content='The Stack Overflow dataset had 8 million pairs of questions and answers.'), HumanMessage(content='Multiply that number by 10.'), AIMessage(content='8 million multiplied by 10 is 80 million.'), HumanMessage(content='Multiply that number by 10.'), AIMessage(content='80 million multiplied by 10 is 800 million.')], 'answer': '80 million multiplied by 10 is 800 million.'}\n"
     ]
    }
   ],
   "source": [
    "q = 'Multiply that number by 10.'\n",
    "result = ask_question(q, crc)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 million multiplied by 10 is 800 million.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='How many pairs of questions and answers had the StackOverflow dataset?'\n",
      "content='The Stack Overflow dataset had 8 million pairs of questions and answers.'\n",
      "content='Multiply that number by 10.'\n",
      "content='8 million multiplied by 10 is 80 million.'\n",
      "content='Multiply that number by 10.'\n",
      "content='80 million multiplied by 10 is 800 million.'\n"
     ]
    }
   ],
   "source": [
    "# Now you can iterate over the chat_history if it exists\n",
    "if 'chat_history' in result:\n",
    "    for i in result['chat_history']:\n",
    "        print(i)\n",
    "else:\n",
    "    print(\"No chat history found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 5})\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "\n",
    "system_template = r'''\n",
    "Use the following pieces of context to answer the user's question.\n",
    "If you don't find the answer in the provided context, just respond \"I don't know.\"\n",
    "---------------\n",
    "Context: ```{context}```\n",
    "'''\n",
    "\n",
    "user_template = '''\n",
    "Question: ```{question}```\n",
    "'''\n",
    "\n",
    "messages= [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(user_template)\n",
    "]\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff',\n",
    "    combine_docs_chain_kwargs={'prompt': qa_prompt },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat Shethia\\AppData\\Local\\Temp\\ipykernel_10416\\409755262.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'How many pairs of questions and answers had the StackOverflow dataset?', 'chat_history': [HumanMessage(content='How many pairs of questions and answers had the StackOverflow dataset?'), AIMessage(content='The Stack Overflow dataset had 8 million pairs of questions and answers.'), HumanMessage(content='Multiply that number by 10.'), AIMessage(content='8 million multiplied by 10 is 80 million.'), HumanMessage(content='Multiply that number by 10.'), AIMessage(content='80 million multiplied by 10 is 800 million.'), HumanMessage(content='How many pairs of questions and answers had the StackOverflow dataset?'), AIMessage(content=\"I don't know.\")], 'answer': \"I don't know.\"}\n"
     ]
    }
   ],
   "source": [
    "db = load_embeddings_chroma()\n",
    "q = 'How many pairs of questions and answers had the StackOverflow dataset?'\n",
    "result = ask_question(q, crc)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'When was Elon Musk born?', 'chat_history': [HumanMessage(content='How many pairs of questions and answers had the StackOverflow dataset?'), AIMessage(content='The Stack Overflow dataset had 8 million pairs of questions and answers.'), HumanMessage(content='Multiply that number by 10.'), AIMessage(content='8 million multiplied by 10 is 80 million.'), HumanMessage(content='Multiply that number by 10.'), AIMessage(content='80 million multiplied by 10 is 800 million.'), HumanMessage(content='How many pairs of questions and answers had the StackOverflow dataset?'), AIMessage(content=\"I don't know.\"), HumanMessage(content='When was Elon Musk born?'), AIMessage(content=\"I don't know.\")], 'answer': \"I don't know.\"}\n"
     ]
    }
   ],
   "source": [
    "q = 'When was Elon Musk born?'\n",
    "result = ask_question(q, crc)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
