{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a ChatGPT App with LangChain from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: who is julius ceasar ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'who is julius ceasar ?', 'text': 'Julius Caesar was a prominent Roman general, statesman, and key figure in the events that led to the demise of the Roman Republic and the rise of the Roman Empire. Born on July 12 or 13, 100 BC, he became known for his military campaigns, particularly the conquest of Gaul, which expanded Rome\\'s territories significantly.\\n\\nCaesar was also involved in Roman politics and played a crucial role in the transformation of the Roman government. He established himself as a dictator and enacted a number of reforms, but his rise to power led to tensions with other leaders in Rome.\\n\\nHis life came to a dramatic end on March 15, 44 BC, when he was assassinated by a group of senators, including some he considered friends. The phrase \"Beware the Ides of March,\" often attributed to a soothsayer in Shakespeare\\'s play about him, warns Caesar of his impending fate. His death prompted a series of civil wars that ultimately led to the establishment of the Roman Empire under his grandnephew and adopted heir, Octavian (later known as Augustus). Caesar\\'s legacy includes his influence on military strategy, governance, and literature, and he is often depicted in various works of art and literature.'}\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=1)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    messages=[\n",
    "#         SystemMessage(content=\"You respond only in German.\"),\n",
    "        SystemMessage(content='You are a chatbot having a conversation with a human.'),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "    if content.lower() in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response = chain.invoke({'content': content})\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Chat Memory Using ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: Earth's Diameter is ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': \"Earth's Diameter is ?\", 'chat_history': [HumanMessage(content=\"Earth's Diameter is ?\"), AIMessage(content=\"The average diameter of Earth is about 12,742 kilometers (7,918 miles). However, this can vary slightly depending on whether you're measuring the equatorial diameter or the polar diameter. The equatorial diameter is approximately 12,756 kilometers (7,926 miles), while the polar diameter is about 12,714 kilometers (7,900 miles), due to the Earth's slightly oblate shape.\")], 'text': \"The average diameter of Earth is about 12,742 kilometers (7,918 miles). However, this can vary slightly depending on whether you're measuring the equatorial diameter or the polar diameter. The equatorial diameter is approximately 12,756 kilometers (7,926 miles), while the polar diameter is about 12,714 kilometers (7,900 miles), due to the Earth's slightly oblate shape.\"}\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: Earth's Diameter is ?\n",
      "AI: The average diameter of Earth is about 12,742 kilometers (7,918 miles). However, this can vary slightly depending on whether you're measuring the equatorial diameter or the polar diameter. The equatorial diameter is approximately 12,756 kilometers (7,926 miles), while the polar diameter is about 12,714 kilometers (7,900 miles), due to the Earth's slightly oblate shape.\n",
      "Human: and its weight is ??\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'and its weight is ??', 'chat_history': [HumanMessage(content=\"Earth's Diameter is ?\"), AIMessage(content=\"The average diameter of Earth is about 12,742 kilometers (7,918 miles). However, this can vary slightly depending on whether you're measuring the equatorial diameter or the polar diameter. The equatorial diameter is approximately 12,756 kilometers (7,926 miles), while the polar diameter is about 12,714 kilometers (7,900 miles), due to the Earth's slightly oblate shape.\"), HumanMessage(content='and its weight is ??'), AIMessage(content='The mass of Earth is approximately \\\\(5.97 \\\\times 10^{24}\\\\) kilograms (about 1.32 × 10²⁵ pounds). While we often refer to \"weight,\" in the context of celestial bodies, we typically talk about mass, which is a measure of the amount of matter in an object. Weight, in the gravitational sense, would depend on the gravitational field strength and is not usually specified for planets.')], 'text': 'The mass of Earth is approximately \\\\(5.97 \\\\times 10^{24}\\\\) kilograms (about 1.32 × 10²⁵ pounds). While we often refer to \"weight,\" in the context of celestial bodies, we typically talk about mass, which is a measure of the amount of matter in an object. Weight, in the gravitational sense, would depend on the gravitational field strength and is not usually specified for planets.'}\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=1)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"chat_history\"],\n",
    "    messages=[\n",
    "#         SystemMessage(content=\"You respond only in German.\"),\n",
    "        SystemMessage(content='You are a chatbot having a conversation with a human.'),\n",
    "        MessagesPlaceholder(variable_name = \"chat_history\"), # Memory Will Be Stored Here\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "    if content.lower() in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response = chain.invoke({'content': content})\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Chat Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'whats my name?', 'chat_history': [HumanMessage(content='Whats the speed of light?'), AIMessage(content=\"The speed of light in a vacuum is approximately 299,792 kilometers per second (or about 186,282 miles per second). In scientific notation, it's often rounded to \\\\(3.00 \\\\times 10^8\\\\) meters per second.\"), HumanMessage(content='whats the speed of light in vaccuum?'), AIMessage(content='The speed of light in a vacuum is approximately 299,792 kilometers per second (about 186,282 miles per second). This value is often represented in scientific notation as \\\\(3.00 \\\\times 10^8\\\\) meters per second.'), HumanMessage(content='whats its spped in a solid like ice?'), AIMessage(content=\"The speed of light in a solid, like ice, is slower than in a vacuum due to the medium's refractive index. For ice, the refractive index is about 1.31. To find the speed of light in ice, you can divide the speed of light in a vacuum by the refractive index:\\n\\n\\\\[\\n\\\\text{Speed of light in ice} = \\\\frac{\\\\text{Speed of light in vacuum}}{\\\\text{Refractive index of ice}} \\\\approx \\\\frac{299,792 \\\\text{ km/s}}{1.31} \\\\approx 229,000 \\\\text{ km/s}\\n\\\\]\\n\\nSo, light travels in ice at approximately 229,000 kilometers per second.\"), HumanMessage(content='list all the questions that ive asked till now'), AIMessage(content='Here are the questions you\\'ve asked so far:\\n\\n1. \"Whats the speed of light?\"\\n2. \"Whats the speed of light in vacuum?\"\\n3. \"Whats its speed in a solid like ice?\" \\n\\nIf you have more questions or need further information, feel free to ask!'), HumanMessage(content='list all the questions that ive asked til now '), AIMessage(content='Sure! Here are all the questions you\\'ve asked so far:\\n\\n1. \"Whats the speed of light?\"\\n2. \"Whats the speed of light in vacuum?\"\\n3. \"Whats its speed in a solid like ice?\"\\n4. \"List all the questions that I\\'ve asked till now.\"\\n5. \"List all the questions that I\\'ve asked til now.\"\\n\\nIf you have more questions or anything else you\\'d like to know, just let me know!'), HumanMessage(content='list all the questions that ive asked til now '), AIMessage(content='Here are all the questions you\\'ve asked so far:\\n\\n1. \"Whats the speed of light?\"\\n2. \"Whats the speed of light in vacuum?\"\\n3. \"Whats its speed in a solid like ice?\"\\n4. \"List all the questions that I\\'ve asked till now.\"\\n5. \"List all the questions that I\\'ve asked til now.\"\\n6. \"List all the questions that I\\'ve asked til now.\" (repeated)\\n\\nIf you have any more questions or need further assistance, feel free to ask!'), HumanMessage(content='list all the questions that ive asked til now '), AIMessage(content='Here are all the questions you\\'ve asked:\\n\\n1. \"Whats the speed of light?\"\\n2. \"Whats the speed of light in vacuum?\"\\n3. \"Whats its speed in a solid like ice?\"\\n4. \"List all the questions that I\\'ve asked till now.\"\\n5. \"List all the questions that I\\'ve asked til now.\"\\n6. \"List all the questions that I\\'ve asked til now.\" (repeated)\\n\\nIf you have any additional questions or need further information, feel free to ask!')], 'text': \"I don't have access to your personal information, including your name, unless you provide it during our conversation. If you'd like to share your name or any other information, feel free!\"}\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1. Import FileChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=1)\n",
    "\n",
    "# 2. Add an additional keyword argument to the ConversationBufferMemory() constructor\n",
    "history = FileChatMessageHistory('chat_history.json')\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"chat_history\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "    if content.lower() in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response = chain.invoke({'content': content})\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
