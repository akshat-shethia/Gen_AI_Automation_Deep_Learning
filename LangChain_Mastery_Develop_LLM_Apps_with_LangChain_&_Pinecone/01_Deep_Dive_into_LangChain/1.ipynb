{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-openai\n",
      "Version: 0.1.23\n",
      "Summary: An integration package connecting OpenAI and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\n",
      "Requires: langchain-core, openai, tiktoken\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is a fundamental theory in physics that describes the behavior of matter and energy at the smallest scales, where particles exhibit both wave-like and particle-like properties, and their states are fundamentally probabilistic rather than deterministic.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(\"Explain Quantum Mechanics in one sentence\", model = \"gpt-4o-mini\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf atomarer und subatomarer Ebene durch probabilistische Wellenfunktionen.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import(\n",
    "    SystemMessage, \n",
    "    AIMessage, \n",
    "    HumanMessage\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content = \"You are a physicist and respond only in German\"),\n",
    "    HumanMessage(content=\"Explain quantum mechanics in one sentence\")\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching LLM Responses\n",
    "- Using Langchain's `InMemoryCache()`\n",
    "- Using `SQLiteCache()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name = \"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = \"Explain quantum mechanics in 5 words\"\n",
    "output = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wave-like behavior of subatomic particles.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWave-like behavior of subatomic particles.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path = \".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 717 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired. \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First request (not in cache, takes longer)\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 361 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired. \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Second request (cached, faster)\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Title: \"Raven's Moonlight\"**\n",
      "\n",
      "(Verse 1)  \n",
      "Underneath the silver glow, where shadows start to creep,  \n",
      "A raven calls from the edge of night, secrets it will keep.  \n",
      "With wings like midnight feathers, it dances on the breeze,  \n",
      "Whispering to the moonlit sky, a song that brings me to my knees.  \n",
      "The stars like diamonds flicker, in a canvas dark and deep,  \n",
      "As the raven soars through the night, while the world around me sleeps.  \n",
      "\n",
      "(Chorus)  \n",
      "Oh, raven of the moonlight, take me where you fly,  \n",
      "Through the mysteries of the night, beneath the endless sky.  \n",
      "We'll chase the dreams that haunt us, with every haunting cry,  \n",
      "In the shadows of the moonlight, together we will rise.  \n",
      "With the fire of the night, and the howl of the wind,  \n",
      "We'll carve our names in starlight, let the wild ride begin!  \n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "prompt = \"Write a rock song about the moon and a raven (2 paras)\"\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main difference between `ChatOpenAI` and `OpenAI` in the langchain_openai library lies in their ***usage and functionality***. `ChatOpenAI` is specifically *designed for chat models*, where the input and output are ***conversational messages***. On the other hand, `OpenAI` is used for *interfacing with language models* (LMS) and is ***NOT specifically tailored for chat interactions***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Verse 1**  \n",
      "In the shadow of the night, where the silver light glows,  \n",
      "A raven takes to flight, with secrets only it knows.  \n",
      "Wings like whispers, cutting through the dark,  \n",
      "It dances with the moon, leaving behind its mark.  \n",
      "Howling winds, they call, while the stars ignite the sky,  \n",
      "Together they weave tales of love and lullabies.  \n",
      "\n",
      "**Chorus**  \n",
      "Oh, moonlight dreams and midnight schemes,  \n",
      "With a raven soaring high, breaking all the seams.  \n",
      "In a world of shadows, where the wild hearts roam,  \n",
      "We’ll chase the night together, never far from home.  "
     ]
    }
   ],
   "source": [
    "for i in llm.stream(prompt):\n",
    "    print(i.content, end = \"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an experienced virologist.\\nWrite a few sentences about the following virus \"Monkey Pox\" in English'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "prompt = prompt_template.format(virus = \"Monkey Pox\", language = \"English\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monkeypox is a viral zoonotic disease caused by the monkeypox virus, which is part of the Orthopoxvirus genus, the same family that includes smallpox. Initially identified in laboratory monkeys in 1958, the virus primarily circulates in certain animal populations in Central and West Africa, but human cases have been reported outside these regions. Transmission to humans can occur through direct contact with infected animals, bodily fluids, or contaminated materials, and it can also spread between humans through respiratory droplets or skin lesions. Symptoms typically include fever, rash, and swollen lymph nodes, and while the disease is generally self-limiting, it can lead to severe complications in some cases. Vaccination against smallpox has been shown to provide some cross-protection against monkeypox."
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name = \"gpt-4o-mini\", temperature=0)\n",
    "output = llm.invoke(prompt).content\n",
    "\n",
    "for i in llm.stream(prompt):\n",
    "    print(i.content, end = \"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format.'), HumanMessage(content='Top 5 countries in World by population.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# Create a chat template with system and human messages\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in the JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in the specific values for n and area\n",
    "messages = chat_template.format_messages(n='5', area='World')\n",
    "print(messages)  # Outputs the formatted chat messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"countries\": [\n",
      "        {\n",
      "            \"rank\": 1,\n",
      "            \"country\": \"China\",\n",
      "            \"population\": \"1,439,323,776\"\n",
      "        },\n",
      "        {\n",
      "            \"rank\": 2,\n",
      "            \"country\": \"India\",\n",
      "            \"population\": \"1,380,004,385\"\n",
      "        },\n",
      "        {\n",
      "            \"rank\": 3,\n",
      "            \"country\": \"United States\",\n",
      "            \"population\": \"331,002,651\"\n",
      "        },\n",
      "        {\n",
      "            \"rank\": 4,\n",
      "            \"country\": \"Indonesia\",\n",
      "            \"population\": \"273,523,615\"\n",
      "        },\n",
      "        {\n",
      "            \"rank\": 5,\n",
      "            \"country\": \"Pakistan\",\n",
      "            \"population\": \"220,892,340\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat Shethia\\AppData\\Local\\Temp\\ipykernel_23320\\4130418131.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an experienced Virologist. Write a few Sentences about the following virus 'Covid-19' in 'english'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'virus': 'Covid-19', 'language': 'english', 'text': 'COVID-19, caused by the novel coronavirus SARS-CoV-2, emerged in late 2019 and quickly led to a global pandemic. The virus primarily spreads through respiratory droplets when an infected person coughs, sneezes, or talks. Symptoms can range from mild respiratory issues to severe pneumonia, and some individuals may remain asymptomatic. Vaccination efforts have been crucial in controlling the spread of the virus and reducing severe illness. Ongoing research continues to monitor variants and their potential impact on transmissibility and vaccine efficacy.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "template = \"You are an experienced Virologist. Write a few Sentences about the following virus '{virus}' in '{language}'.\"\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_template,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "ouptut = chain.invoke({\"virus\": \"Covid-19\", \"language\": \"english\"})\n",
    "print(ouptut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of India? List the top 3 places to visit in that country. Use Bullet Points\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The capital of India is New Delhi. Here are the top 3 places to visit in the country:\n",
      "\n",
      "- **Taj Mahal (Agra)**: A UNESCO World Heritage Site and an iconic symbol of love, this stunning marble mausoleum attracts millions of visitors each year.\n",
      "  \n",
      "- **Jaipur (Rajasthan)**: Known as the \"Pink City,\" Jaipur is famous for its majestic forts, palaces, and vibrant markets, including the Hawa Mahal and Amber Fort.\n",
      "  \n",
      "- **Varanasi (Uttar Pradesh)**: One of the oldest living cities in the world, Varanasi is a significant cultural and spiritual center, known for its ghats along the Ganges River and its rich traditions.\n"
     ]
    }
   ],
   "source": [
    "template = \"What is the capital of {country}? List the top 3 places to visit in that country. Use Bullet Points\"\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_template,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "country = input(\"Enter the name of a country: \")\n",
    "output = chain.invoke(country)\n",
    "print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mCertainly! Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. In its simplest form, simple linear regression involves fitting a straight line to a set of data points.\n",
      "\n",
      "Here's a Python function that implements simple linear regression using the least squares method. This function will calculate the slope and intercept of the regression line and can also make predictions based on the model.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def linear_regression(x, y):\n",
      "    \"\"\"\n",
      "    Perform simple linear regression on the given data.\n",
      "\n",
      "    Parameters:\n",
      "    x (array-like): Independent variable (predictor).\n",
      "    y (array-like): Dependent variable (response).\n",
      "\n",
      "    Returns:\n",
      "    slope (float): Slope of the regression line.\n",
      "    intercept (float): Intercept of the regression line.\n",
      "    predictions (array): Predicted values based on the regression line.\n",
      "    \"\"\"\n",
      "    # Convert x and y to numpy arrays\n",
      "    x = np.array(x)\n",
      "    y = np.array(y)\n",
      "\n",
      "    # Calculate the number of observations\n",
      "    n = len(x)\n",
      "\n",
      "    # Calculate the slope (m) and intercept (b)\n",
      "    x_mean = np.mean(x)\n",
      "    y_mean = np.mean(y)\n",
      "\n",
      "    # Using the least squares formula\n",
      "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
      "    denominator = np.sum((x - x_mean) ** 2)\n",
      "\n",
      "    slope = numerator / denominator\n",
      "    intercept = y_mean - (slope * x_mean)\n",
      "\n",
      "    # Calculate predictions\n",
      "    predictions = slope * x + intercept\n",
      "\n",
      "    return slope, intercept, predictions\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    # Sample data\n",
      "    x = [1, 2, 3, 4, 5]\n",
      "    y = [2, 3, 5, 7, 11]\n",
      "\n",
      "    # Perform linear regression\n",
      "    slope, intercept, predictions = linear_regression(x, y)\n",
      "\n",
      "    print(f\"Slope: {slope}\")\n",
      "    print(f\"Intercept: {intercept}\")\n",
      "\n",
      "    # Plotting the results\n",
      "    plt.scatter(x, y, color='blue', label='Data Points')\n",
      "    plt.plot(x, predictions, color='red', label='Regression Line')\n",
      "    plt.xlabel('Independent Variable (x)')\n",
      "    plt.ylabel('Dependent Variable (y)')\n",
      "    plt.title('Simple Linear Regression')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Function Definition**: The `linear_regression` function takes two parameters, `x` and `y`, which are the independent and dependent variables, respectively.\n",
      "2. **Mean Calculation**: It calculates the means of `x` and `y`.\n",
      "3. **Slope and Intercept Calculation**: It uses the least squares method to determine the slope and intercept of the regression line.\n",
      "4. **Predictions**: The function calculates the predicted values based on the regression line.\n",
      "5. **Example Usage**: The script includes an example dataset and demonstrates how to call the function, print the results, and plot the data along with the regression line.\n",
      "\n",
      "You can run this code in a Python environment with `numpy` and `matplotlib` installed to see the results visually.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe provided Python function `linear_regression` implements a simple form of linear regression, which is a core statistical method for modeling the relationship between a dependent variable (often referred to as the response or outcome variable) and one independent variable (the predictor or feature). Let’s dive into the various components of the function, explaining how they operate and their significance.\n",
      "\n",
      "### Function Breakdown\n",
      "\n",
      "1. **Imports**:\n",
      "   ```python\n",
      "   import numpy as np\n",
      "   import matplotlib.pyplot as plt\n",
      "   ```\n",
      "   - **NumPy**: A fundamental package for scientific computing in Python. It provides support for arrays and mathematical functions.\n",
      "   - **Matplotlib**: A plotting library in Python for data visualization. It is used here to visualize the data points and the regression line.\n",
      "\n",
      "2. **Function Definition**:\n",
      "   ```python\n",
      "   def linear_regression(x, y):\n",
      "   ```\n",
      "   - The function `linear_regression` takes in two arguments: `x` and `y`, which should contain the independent and dependent variable data, respectively.\n",
      "\n",
      "3. **Convert to NumPy Arrays**:\n",
      "   ```python\n",
      "   x = np.array(x)\n",
      "   y = np.array(y)\n",
      "   ```\n",
      "   - Both `x` and `y` are converted into NumPy arrays for easier manipulation and operations. This allows for element-wise calculations when necessary.\n",
      "\n",
      "4. **Calculate Number of Observations**:\n",
      "   ```python\n",
      "   n = len(x)\n",
      "   ```\n",
      "   - The number of data points, `n`, is determined by finding the length of the array `x`.\n",
      "\n",
      "5. **Calculate Means**:\n",
      "   ```python\n",
      "   x_mean = np.mean(x)\n",
      "   y_mean = np.mean(y)\n",
      "   ```\n",
      "   - The mean (average) of each array is computed, which will be used in calculating the slope and intercept of the regression line.\n",
      "\n",
      "6. **Compute Slope and Intercept**:\n",
      "   - **Slope Calculation**:\n",
      "     ```python\n",
      "     numerator = np.sum((x - x_mean) * (y - y_mean))\n",
      "     denominator = np.sum((x - x_mean) ** 2)\n",
      "\n",
      "     slope = numerator / denominator\n",
      "     ```\n",
      "     - The **numerator** represents the covariance between `x` and `y`, calculated as the sum of the products of the deviations of each data point from their respective means.\n",
      "     - The **denominator** is the variance of `x`, calculated as the sum of the squares of the deviations of `x` from its mean.\n",
      "     - The slope `m` of the regression line is derived from the ratio of covariance to variance.\n",
      "\n",
      "   - **Intercept Calculation**:\n",
      "     ```python\n",
      "     intercept = y_mean - (slope * x_mean)\n",
      "     ```\n",
      "     - The intercept `b` is determined by adjusting the mean of `y` based on how much `x` contributes to `y` through the slope.\n",
      "\n",
      "7. **Predictions**:\n",
      "   ```python\n",
      "   predictions = slope * x + intercept\n",
      "   ```\n",
      "   - This formula uses the linear equation \\( y = mx + b \\) to compute predicted values based on the fitted regression line for each `x` data point.\n",
      "\n",
      "8. **Return Values**:\n",
      "   ```python\n",
      "   return slope, intercept, predictions\n",
      "   ```\n",
      "   - The function returns three primary pieces of information: the calculated slope, intercept, and the predicted values.\n",
      "\n",
      "### Example Usage\n",
      "\n",
      "- In the main script:\n",
      "  ```python\n",
      "  if __name__ == \"__main__\":\n",
      "  ```\n",
      "  - This block ensures that the code runs only if the script is executed directly, facilitating better modular programming.\n",
      "\n",
      "- **Sample Data**:\n",
      "  ```python\n",
      "  x = [1, 2, 3, 4, 5]\n",
      "  y = [2, 3, 5, 7, 11]\n",
      "  ```\n",
      "  - A small dataset of `x` and `y` values is presented as an example for regression analysis.\n",
      "\n",
      "- **Perform Linear Regression**:\n",
      "  ```python\n",
      "  slope, intercept, predictions = linear_regression(x, y)\n",
      "  ```\n",
      "  - Calling the `linear_regression` function processes the data and returns the slope, intercept, and predictions.\n",
      "\n",
      "- **Output**:\n",
      "  ```python\n",
      "  print(f\"Slope: {slope}\")\n",
      "  print(f\"Intercept: {intercept}\")\n",
      "  ```\n",
      "  - The slope and intercept values are printed, indicating the relationship's parameters.\n",
      "\n",
      "### Data Visualization\n",
      "\n",
      "- **Plotting**:\n",
      "  ```python\n",
      "  plt.scatter(x, y, color='blue', label='Data Points')\n",
      "  plt.plot(x, predictions, color='red', label='Regression Line')\n",
      "  plt.xlabel('Independent Variable (x)')\n",
      "  plt.ylabel('Dependent Variable (y)')\n",
      "  plt.title('Simple Linear Regression')\n",
      "  plt.legend()\n",
      "  plt.show()\n",
      "  ```\n",
      "  - The data points are displayed as blue dots, while the fitted regression line comes in red.\n",
      "  - The plot includes axis labels and a title, along with a legend that distinguishes between the data points and regression line.\n",
      "\n",
      "### Conclusion\n",
      "This function showcases essential concepts of linear regression, including data processing, statistical calculations, and visualization, all while employing common Python libraries. It serves as a sound example of how to implement a foundational machine learning algorithm in Python succinctly, providing insights into the relationships of bivariate datasets systematically. By running this code, users can evaluate their results and understand the implementation of simple linear regression.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Initialize the first ChatOpenAI model (gpt-4o-mini) with specific temperature\n",
    "llm1 = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.5)\n",
    "\n",
    "# Define the first prompt template\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template='You are an experienced scientist and Python programmer. Write a function that implements the concept of {concept}.'\n",
    ")\n",
    "# Create an LLMChain using the first model and the prompt template\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "# Initialize the second ChatOpenAI model (gpt-4o-mini) with specific temperature\n",
    "llm2 = ChatOpenAI(model_name='gpt-4o-mini', temperature=1.2)\n",
    "\n",
    "# Define the second prompt template\n",
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "# Create another LLMChain using the second model and the prompt template\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "\n",
    "# Combine both chains into a SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "# Invoke the overall chain with the concept \"linear regression\"\n",
    "output = overall_chain.invoke('linear regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided Python function `linear_regression` implements a simple form of linear regression, which is a core statistical method for modeling the relationship between a dependent variable (often referred to as the response or outcome variable) and one independent variable (the predictor or feature). Let’s dive into the various components of the function, explaining how they operate and their significance.\n",
      "\n",
      "### Function Breakdown\n",
      "\n",
      "1. **Imports**:\n",
      "   ```python\n",
      "   import numpy as np\n",
      "   import matplotlib.pyplot as plt\n",
      "   ```\n",
      "   - **NumPy**: A fundamental package for scientific computing in Python. It provides support for arrays and mathematical functions.\n",
      "   - **Matplotlib**: A plotting library in Python for data visualization. It is used here to visualize the data points and the regression line.\n",
      "\n",
      "2. **Function Definition**:\n",
      "   ```python\n",
      "   def linear_regression(x, y):\n",
      "   ```\n",
      "   - The function `linear_regression` takes in two arguments: `x` and `y`, which should contain the independent and dependent variable data, respectively.\n",
      "\n",
      "3. **Convert to NumPy Arrays**:\n",
      "   ```python\n",
      "   x = np.array(x)\n",
      "   y = np.array(y)\n",
      "   ```\n",
      "   - Both `x` and `y` are converted into NumPy arrays for easier manipulation and operations. This allows for element-wise calculations when necessary.\n",
      "\n",
      "4. **Calculate Number of Observations**:\n",
      "   ```python\n",
      "   n = len(x)\n",
      "   ```\n",
      "   - The number of data points, `n`, is determined by finding the length of the array `x`.\n",
      "\n",
      "5. **Calculate Means**:\n",
      "   ```python\n",
      "   x_mean = np.mean(x)\n",
      "   y_mean = np.mean(y)\n",
      "   ```\n",
      "   - The mean (average) of each array is computed, which will be used in calculating the slope and intercept of the regression line.\n",
      "\n",
      "6. **Compute Slope and Intercept**:\n",
      "   - **Slope Calculation**:\n",
      "     ```python\n",
      "     numerator = np.sum((x - x_mean) * (y - y_mean))\n",
      "     denominator = np.sum((x - x_mean) ** 2)\n",
      "\n",
      "     slope = numerator / denominator\n",
      "     ```\n",
      "     - The **numerator** represents the covariance between `x` and `y`, calculated as the sum of the products of the deviations of each data point from their respective means.\n",
      "     - The **denominator** is the variance of `x`, calculated as the sum of the squares of the deviations of `x` from its mean.\n",
      "     - The slope `m` of the regression line is derived from the ratio of covariance to variance.\n",
      "\n",
      "   - **Intercept Calculation**:\n",
      "     ```python\n",
      "     intercept = y_mean - (slope * x_mean)\n",
      "     ```\n",
      "     - The intercept `b` is determined by adjusting the mean of `y` based on how much `x` contributes to `y` through the slope.\n",
      "\n",
      "7. **Predictions**:\n",
      "   ```python\n",
      "   predictions = slope * x + intercept\n",
      "   ```\n",
      "   - This formula uses the linear equation \\( y = mx + b \\) to compute predicted values based on the fitted regression line for each `x` data point.\n",
      "\n",
      "8. **Return Values**:\n",
      "   ```python\n",
      "   return slope, intercept, predictions\n",
      "   ```\n",
      "   - The function returns three primary pieces of information: the calculated slope, intercept, and the predicted values.\n",
      "\n",
      "### Example Usage\n",
      "\n",
      "- In the main script:\n",
      "  ```python\n",
      "  if __name__ == \"__main__\":\n",
      "  ```\n",
      "  - This block ensures that the code runs only if the script is executed directly, facilitating better modular programming.\n",
      "\n",
      "- **Sample Data**:\n",
      "  ```python\n",
      "  x = [1, 2, 3, 4, 5]\n",
      "  y = [2, 3, 5, 7, 11]\n",
      "  ```\n",
      "  - A small dataset of `x` and `y` values is presented as an example for regression analysis.\n",
      "\n",
      "- **Perform Linear Regression**:\n",
      "  ```python\n",
      "  slope, intercept, predictions = linear_regression(x, y)\n",
      "  ```\n",
      "  - Calling the `linear_regression` function processes the data and returns the slope, intercept, and predictions.\n",
      "\n",
      "- **Output**:\n",
      "  ```python\n",
      "  print(f\"Slope: {slope}\")\n",
      "  print(f\"Intercept: {intercept}\")\n",
      "  ```\n",
      "  - The slope and intercept values are printed, indicating the relationship's parameters.\n",
      "\n",
      "### Data Visualization\n",
      "\n",
      "- **Plotting**:\n",
      "  ```python\n",
      "  plt.scatter(x, y, color='blue', label='Data Points')\n",
      "  plt.plot(x, predictions, color='red', label='Regression Line')\n",
      "  plt.xlabel('Independent Variable (x)')\n",
      "  plt.ylabel('Dependent Variable (y)')\n",
      "  plt.title('Simple Linear Regression')\n",
      "  plt.legend()\n",
      "  plt.show()\n",
      "  ```\n",
      "  - The data points are displayed as blue dots, while the fitted regression line comes in red.\n",
      "  - The plot includes axis labels and a title, along with a legend that distinguishes between the data points and regression line.\n",
      "\n",
      "### Conclusion\n",
      "This function showcases essential concepts of linear regression, including data processing, statistical calculations, and visualization, all while employing common Python libraries. It serves as a sound example of how to implement a foundational machine learning algorithm in Python succinctly, providing insights into the relationships of bivariate datasets systematically. By running this code, users can evaluate their results and understand the implementation of simple linear regression.\n"
     ]
    }
   ],
   "source": [
    "print(output[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-experimental\n",
      "Version: 0.0.64\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\n",
      "Requires: langchain-community, langchain-core\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1, 100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate 2 + 2 using Python, I will execute the addition operation in the Python REPL.  \n",
      "Action: Python_REPL  \n",
      "Action Input: print(2 + 2)  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
      "Final Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate 2 + 2 using Python', 'output': '4'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Calculate 2 + 2 using Python'\n",
    "agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate the square root of the factorial of 12, I need to first compute the factorial of 12 and then take the square root of that result. I will use the `math` module in Python, which provides a function for calculating factorials and another for calculating square roots.\n",
      "\n",
      "Action: Python_REPL  \n",
      "Action Input: `import math; result = math.sqrt(math.factorial(12)); result`  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to print the result to see the output.  \n",
      "Action: Python_REPL  \n",
      "Action Input: `import math; result = math.sqrt(math.factorial(12)); print(result)`  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.105181141756\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
      "Final Answer: 21886.105181141756\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 using Python',\n",
       " 'output': '21886.105181141756'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Calculate the square root of the factorial of 12 using Python'\n",
    "agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate the square root of the factorial of 12, I will first compute the factorial of 12, then take the square root of that result. Finally, I will format the output to display it with 4 decimal points. \n",
      "\n",
      "Action: Python_REPL  \n",
      "Action Input: `import math; result = math.sqrt(math.factorial(12)); format_result = format(result, '.4f'); format_result`  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check the output of the code to see the result of the calculation. \n",
      "\n",
      "Action: Python_REPL  \n",
      "Action Input: `import math; result = math.sqrt(math.factorial(12)); format_result = format(result, '.4f'); format_result`  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I don't know`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1359\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1359\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:807\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:79\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[0;32m     82\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     83\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[0;32m     87\u001b[0m ):\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `I don't know`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Invoke the agent\u001b[39;00m\n\u001b[0;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculate the square root of the factorial of 12 and display it with 4 decimal points\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:164\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    163\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    165\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:154\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 154\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    160\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1625\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1634\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1635\u001b[0m         )\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1331\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1324\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1331\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1341\u001b[0m     )\n",
      "File \u001b[1;32mc:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1370\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m-> 1370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m     )\n\u001b[0;32m   1376\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I don't know`"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "# Create a Python agent using the ChatOpenAI model and a PythonREPLTool\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True  # Add this argument to handle parsing errors\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "prompt = 'Calculate the square root of the factorial of 12 and display it with 4 decimal points'\n",
    "agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: duckduckgo_search\n",
      "Version: 6.2.11\n",
      "Summary: Search for words, documents, images, news, maps and text translation using the DuckDuckGo.com search engine.\n",
      "Home-page: https://github.com/deedy5/duckduckgo_search\n",
      "Author: deedy5\n",
      "Author-email: \n",
      "License: MIT License\n",
      "Location: c:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\n",
      "Requires: click, primp\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freddie Mercury (born September 5, 1946, Stone Town, Zanzibar [now in Tanzania]—died November 24, 1991, Kensington, London, England) was a British rock singer and songwriter whose flamboyant showmanship and powerfully agile vocals, most famously for the band Queen, made him one of rock's most dynamic front men.. Bulsara was born to Parsi parents who had emigrated from India to Zanzibar ... Freddie Mercury was born Farrokh Bulsara in Stone Town in the British protectorate of the Sultanate of Zanzibar, East Africa (now part of Tanzania) on September 5, 1946. When did he get his start in music? Freddie Mercury began his musical career in the late 1960s. He formed his first band, The Hectics, while attending St. Peter's School in ... Freddie Mercury was Britain's first Indian rock star. This fact and the nature of his sexuality were the two areas of his short life about which he would be intentionally obscure. Although he was born on the East African island of Zanzibar on September 5, 1946, his parents were both Indian; they were Parsees from Gujarat. On September 5, 1946, a future music icon called Farrokh Bulsara was born in Zanzibar to his Parsi parents. Taking on the stage name of Freddie Mercury, he would go on to become one of the ... The great architect of vocal grandeur, Freddie Mercury, born on September 5th, 1946, blessed the world with a voice that seemed to descend from the heavens, only to then tear the earth asunder with its power.His legacy, entwined with the brilliance of Queen, set an unyielding standard for rock 'n' roll.Mercury was more than just a frontman—he was a creator, a visionary, and a spirit that ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "output = search.invoke(\"Where was Freddie Mercury Born?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('duckduckgo_search',\n",
       " 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name, search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[snippet: Freddie Mercury (born September 5, 1946, Stone Town, Zanzibar [now in Tanzania]—died November 24, 1991, Kensington, London, England) was a British rock singer and songwriter whose flamboyant showmanship and powerfully agile vocals, most famously for the band Queen, made him one of rock's most dynamic front men.. Bulsara was born to Parsi parents who had emigrated from India to Zanzibar ..., title: Freddie Mercury | Biography, Parents, Songs, & Facts, link: https://www.britannica.com/biography/Freddie-Mercury], [snippet: Freddie Mercury was a larger than life figure, ... Freddie Mercury Queen. 3 of the Most Historic Moments of Freddie Mercury's Iconic Career. By. Peter Burditt. Updated: September 5, 2024 3:24 pm., title: 3 of the Most Historic Moments of Freddie Mercury's Iconic Career, link: https://americansongwriter.com/3-of-the-most-historic-moments-of-freddie-mercurys-iconic-career/], [snippet: Queen are a British rock band formed in London in 1970 by Freddie Mercury (lead vocals, piano), Brian May (guitar, vocals), and Roger Taylor (drums, vocals),..., title: Queen Greatest Hits - YouTube, link: https://www.youtube.com/watch?v=CfymLdtaFOQ], [snippet: Freddie Mercury's flamboyant stage presence and powerful vocals are undeniably iconic, but his influence goes far beyond the music. His bond with his Queen bandmates, Brian May, John Deacon, and Roger Taylor, was a key part of the band's success. These four men shared a unique creative partnership, experiencing the highs and lows of fame ..., title: Freddie Mercury's Real Relationship With His Bandmates In Queen, link: https://iloveclassicrock.com/freddie-mercurys-real-relationship-with-his-bandmates-in-queen/]\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.invoke(\"Freddie Mercury and Queen\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[snippet: The coldest month is January, with high temperatures in the low 70s F (about 21 °C) and low temperatures in the mid-40s F (about 7 °C). Delhi, city and national capital territory in north-central India. The city of Delhi actually consists of two components: Old Delhi, in the north, the historic city; and New Delhi, in the south, since 1947 ..., title: Delhi | History, Population, Map, & Facts | Britannica, link: https://www.britannica.com/place/Delhi], [snippet: New Delhi, national capital of India. It is situated in the north-central part of the country on the west bank of the Yamuna River, adjacent to and just south of Delhi city (Old Delhi) and within the Delhi national capital territory. In December 1911 King George V of Britain decreed that the capital of British India would be moved from Calcutta ..., title: New Delhi | History, Population, Map, & Facts | Britannica, link: https://www.britannica.com/place/New-Delhi], [snippet: Delhi is both a union territory within India, as well as a city, and features two very different worlds: New Delhi and Old Delhi. The former, inaugurated by the British in 1931 to serve as the imperial capital, is the nation's modern capital and seat of government, while Old Delhi is considered by many as the symbolic heart of the greater metropolitan area., title: 21 Top-Rated Tourist Attractions in Delhi & New Delhi, link: https://www.planetware.com/tourist-attractions-/delhi-ind-delhi-delhi.htm], [snippet: This mosque is one of the largest in Delhi, able to hold a whopping 25,000 people at a time, and is one of the most impressive structures in the city. One highlight is climbing to the top of one of the minarets for a wonderful view over Old Delhi. It's so worth doing, even though the staircase is cramped, dark, and daunting to walk up/down., title: How to Spend Three Perfect Days in Delhi: An In-Depth Itinerary, link: https://www.neverendingfootsteps.com/three-days-new-delhi-itinerary/]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "# Set region to India\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region='in', max_results=3, safesearch='moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source='news')\n",
    "output = search.run('Delhi')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippet: The coldest month is January, with high temperatures in the low 70s F (about 21 °C) and low temperatures in the mid-40s F (about 7 °C). Delhi, city and national capital territory in north-central India. The city of Delhi actually consists of two components: Old Delhi, in the north, the historic city; and New Delhi, in the south, since 1947 ...\n",
      "Title: Delhi | History, Population, Map, & Facts | Britannica\n",
      "Link: https://www.britannica.com/place/Delhi\n",
      "\n",
      "--------------------------------------------------\n",
      "Snippet: New Delhi, national capital of India. It is situated in the north-central part of the country on the west bank of the Yamuna River, adjacent to and just south of Delhi city (Old Delhi) and within the Delhi national capital territory. In December 1911 King George V of Britain decreed that the capital of British India would be moved from Calcutta ...\n",
      "Title: New Delhi | History, Population, Map, & Facts | Britannica\n",
      "Link: https://www.britannica.com/place/New-Delhi\n",
      "\n",
      "--------------------------------------------------\n",
      "Snippet: Delhi is both a union territory within India, as well as a city, and features two very different worlds: New Delhi and Old Delhi. The former, inaugurated by the British in 1931 to serve as the imperial capital, is the nation's modern capital and seat of government, while Old Delhi is considered by many as the symbolic heart of the greater metropolitan area.\n",
      "Title: 21 Top-Rated Tourist Attractions in Delhi & New Delhi\n",
      "Link: https://www.planetware.com/tourist-attractions-/delhi-ind-delhi-delhi.htm\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'snippet: (.*?), title: (.*?), link: (.*?)\\],'\n",
    "matches = re.findall(pattern, output, re.DOTALL)\n",
    "\n",
    "for snippet, title, link in matches:\n",
    "    print(f'Snippet: {snippet}\\nTitle: {title}\\nLink: {link}\\n')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchainhub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Gen_AI_Automation_Deep_Learning\\LangChain_Mastery_Develop_LLM_Apps_with_LangChain_&_Pinecone\\venv\\Lib\\site-packages\\langsmith\\client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model (gpt-4o-mini) with a temperature of 0. Utilize gpt-3.5-turbo if you use the free plan\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# Define a template for answering questions\n",
    "template = '''\n",
    "Answer the following questions in ENGLISH as best you can.\n",
    "Questions: {q}\n",
    "'''\n",
    "\n",
    "# Create a PromptTemplate object from the template\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Pull the react prompt from the hub\n",
    "prompt = hub.pull('hwchase17/react')\n",
    "\n",
    "# displaying information about the react prompt\n",
    "# print(type(prompt))\n",
    "# print(prompt.input_variables)\n",
    "# print(prompt.template)\n",
    "\n",
    "# Create tools for the agent\n",
    "\n",
    "# 1. Python REPL Tool (for executing Python code)\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(\n",
    "    name='Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Useful when you need to use Python to answer a question. You should input Python code.'\n",
    ")\n",
    "\n",
    "# 2. Wikipedia Tool (for searching Wikipedia)\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia.run,\n",
    "    description='Useful for when you need to look up a topic, country, or person on Wikipedia.'\n",
    ")\n",
    "\n",
    "# 3. DuckDuckGo Search Tool (for general web searches)\n",
    "search = DuckDuckGoSearchRun()\n",
    "duckduckgo_tool = Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func=search.run,\n",
    "    description='Useful for when you need to perform an internet search to find information that another tool can\\'t provide.'\n",
    ")\n",
    "\n",
    "# Combine the tools into a list\n",
    "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
    "\n",
    "# Create a react agent with the ChatOpenAI model, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Initialize the AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo generate the first 20 numbers in the Fibonacci series, I can use a simple algorithm that starts with the first two numbers (0 and 1) and then continues to add the last two numbers to get the next one in the series. \n",
      "\n",
      "Action: Python REPL  \n",
      "Action Input: \n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_series = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        next_fib = fib_series[-1] + fib_series[-2]\n",
      "        fib_series.append(next_fib)\n",
      "    return fib_series\n",
      "\n",
      "fibonacci(20)\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI have generated the first 20 numbers in the Fibonacci series. \n",
      "\n",
      "Final Answer: The first 20 numbers in the Fibonacci series are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181].\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# question = 'Generate the first 20 numbers in the Fibonacci series.'\n",
    "# question = 'Who is the current prime minister of the UK?'\n",
    "question = 'Generate the first 20 numbers in the Fibonacci series.'\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 20 numbers in the Fibonacci series are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181].\n"
     ]
    }
   ],
   "source": [
    "print(output[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question about Napoleon Bonaparte's early life, I will look up relevant information on Wikipedia, as it is a reliable source for historical figures.\n",
      "\n",
      "Action: Wikipedia  \n",
      "Action Input: \"Napoleon Bonaparte early life\"  \n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Napoleon\n",
      "Summary: Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 May 1821), later known by his regnal name Napoleon I, was a French military officer and statesman who rose to prominence during the French Revolution and led a series of successful campaigns across Europe during the French Revolutionary and Napoleonic Wars from 1796 to 1815. He was the leader of the French Republic as First Consul from 1799 to 1804, then of the French Empire as Emperor of the French from 1804 to 1814, and briefly again in 1815.\n",
      "Born on the island of Corsica to a family of Italian origin, Napoleon moved to mainland France in 1779 and was commissioned as an officer in the French Royal Army in 1785. He supported the French Revolution in 1789, and promoted its cause in Corsica. He rose rapidly through the ranks after winning the siege of Toulon in 1793 and defeating royalist insurgents in Paris on 13 Vendémiaire in 1795. In 1796, Napoleon commanded a military campaign against the Austrians and their Italian allies in the War of the First Coalition, scoring decisive victories and becoming a national hero. He led an invasion of Egypt and Syria in 1798 which served as a springboard to political power. In November 1799, Napoleon engineered the Coup of 18 Brumaire against the Directory, and became First Consul of the Republic. He won the Battle of Marengo in 1800, which secured France's victory in the War of the Second Coalition, and in 1803 sold the territory of Louisiana to the United States. In December 1804, Napoleon crowned himself Emperor of the French, further expanding his power.\n",
      "The breakdown of the Treaty of Amiens led to the War of the Third Coalition by 1805. Napoleon shattered the coalition with a decisive victory at the Battle of Austerlitz, which led to the dissolution of the Holy Roman Empire. In the War of the Fourth Coalition, Napoleon defeated Prussia at the Battle of Jena–Auerstedt in 1806, marched his Grande Armée into Eastern Europe, and defeated the Russians in 1807 at the Battle of Friedland. Seeking to extend his trade embargo against Britain, Napoleon invaded the Iberian Peninsula and installed his brother Joseph as King of Spain in 1808, provoking the Peninsular War. In 1809, the Austrians again challenged France in the War of the Fifth Coalition, in which Napoleon solidified his grip over Europe after winning the Battle of Wagram. In summer 1812, he launched an invasion of Russia, which ended in the catastrophic retreat of his army that winter. In 1813, Prussia and Austria joined Russia in the War of the Sixth Coalition, in which Napoleon was decisively defeated at the Battle of Leipzig. The coalition invaded France and captured Paris, forcing Napoleon to abdicate in April 1814. They exiled him to the Mediterranean island of Elba and restored the Bourbons to power. In February 1815, Napoleon escaped from Elba and again took control of France in what became known as the \"Hundred Days\". His opponents responded by forming a Seventh Coalition, which defeated him at the Battle of Waterloo in June 1815. Napoleon was exiled to the remote island of Saint Helena in the South Atlantic, where he died of stomach cancer in 1821, aged 51.\n",
      "Napoleon is considered one of the greatest military commanders in history and Napoleonic tactics are still studied at military schools worldwide. His legacy endures through the modernizing legal and administrative reforms he enacted in France and Western Europe, embodied in the Napoleonic Code. He established a system of public education, abolished the vestiges of feudalism, emancipated Jews and other religious minorities, abolished the Spanish Inquisition, enacted the principle of equality before the law for an emerging middle class, and centralized state power at the expense of religious authorities. His conquests acted as a catalyst for political change and the development of nation states. However, he is controversial due to his role in wars which devastated Europe, his looti\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered sufficient information about Napoleon Bonaparte's early life from the Wikipedia summary. \n",
      "\n",
      "Final Answer: Napoleon Bonaparte was born on August 15, 1769, on the island of Corsica to a family of Italian origin. He moved to mainland France in 1779 and was commissioned as an officer in the French Royal Army in 1785. He supported the French Revolution in 1789 and quickly rose through the military ranks, gaining recognition for his victories, including the siege of Toulon in 1793. By 1796, he commanded a military campaign against the Austrians and their Italian allies, becoming a national hero. His early military successes laid the groundwork for his later political power, culminating in his rise to First Consul of the Republic in 1799.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# question = 'Generate the first 20 numbers in the Fibonacci series.'\n",
    "# question = 'Who is the current prime minister of the UK?'\n",
    "question = 'Tell me about Napoleon Bonaparte early life'\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Napoleon Bonaparte was born on August 15, 1769, on the island of Corsica to a family of Italian origin. He moved to mainland France in 1779 and was commissioned as an officer in the French Royal Army in 1785. He supported the French Revolution in 1789 and quickly rose through the military ranks, gaining recognition for his victories, including the siege of Toulon in 1793. By 1796, he commanded a military campaign against the Austrians and their Italian allies, becoming a national hero. His early military successes laid the groundwork for his later political power, culminating in his rise to First Consul of the Republic in 1799.\n"
     ]
    }
   ],
   "source": [
    "print(output[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
