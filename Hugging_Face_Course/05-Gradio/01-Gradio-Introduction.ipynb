{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb609a7a-34fa-4f49-a882-bf7100ce1cac",
   "metadata": {},
   "source": [
    "# Introduction to Gradio\n",
    "\n",
    "## Purpose and Benefits\n",
    "\n",
    "Gradio is an open-source Python library that simplifies the process of creating interfaces for machine learning models. It allows developers and researchers to quickly build customizable web-based UIs for their models. The main advantages of using Gradio include:\n",
    "\n",
    "- **Ease of Use**: Gradio makes it easy for anyone, regardless of their web development expertise, to create and share interactive demos of machine learning models.\n",
    "- **Rapid Prototyping**: You can develop and iterate on your model's interface quickly, making it an ideal tool for experimentation and prototype development.\n",
    "- **Accessibility**: By providing a simple way to interact with models via the web, Gradio helps in democratizing access to AI technology, making it accessible to a non-technical audience.\n",
    "- **Collaboration and Sharing**: Gradio interfaces can be shared with a link, enabling easy collaboration and feedback gathering from users or stakeholders anywhere in the world.\n",
    "\n",
    "## Installation Guide\n",
    "\n",
    "To get started with Gradio, you first need to install the library. You can install Gradio using pip:\n",
    "\n",
    "```bash\n",
    "pip install gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca5fd0-9958-4e30-bafe-a71d40704e3e",
   "metadata": {},
   "source": [
    "# Basics of Gradio\n",
    "\n",
    "## Creating Your First Interface\n",
    "\n",
    "To start using Gradio, let's create a simple interface for a function that adds two numbers. This will demonstrate how you can turn a Python function into an interactive web app with just a few lines of code.\n",
    "\n",
    "First, define the Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6046597-bf18-4f16-b0fe-4eeb487aa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa8a50-12d8-435f-94ad-f411530273cc",
   "metadata": {},
   "source": [
    "Next, create a Gradio interface for this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3867ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-4.42.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Using cached fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: ffmpy in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Using cached gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.24.6)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (6.4.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (3.9.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.6.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.12.4)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio) (0.30.6)\n",
      "Requirement already satisfied: fsspec in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
      "Requirement already satisfied: requests in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Using cached starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\akshat shethia\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\miniconda\\gen_ai_automation_deep_learning\\hugging_face_course\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Using cached gradio-4.42.0-py3-none-any.whl (16.8 MB)\n",
      "Using cached gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
      "Using cached starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: httpcore, anyio, starlette, httpx, gradio-client, fastapi, gradio\n",
      "Successfully installed anyio-4.4.0 fastapi-0.112.1 gradio-4.42.0 gradio-client-1.3.0 httpcore-1.0.5 httpx-0.27.0 starlette-0.38.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3845b060-7748-4d48-94db-db9c21796eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(fn=add_numbers, inputs=[gr.Number(10), gr.Number()], outputs=gr.Number())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca3607-6cc7-4cd9-a7a6-0d9cc1853b0b",
   "metadata": {},
   "source": [
    "This code snippet does the following:\n",
    "\n",
    "- `gr.Interface` creates a new Gradio interface. The `fn` parameter takes the function we defined earlier (`add_numbers`).\n",
    "- The `inputs` parameter specifies that our function requires two numeric inputs.\n",
    "    - `gr.Number()` accepts various [arguments](https://www.gradio.app/docs/gradio/number), such as default values and min/max values.\n",
    "- The `outputs` parameter indicates that our function returns a numeric output.\n",
    "- `iface.launch()` launches the interface. By default, it will be served locally and be accessible via a web browser at `http://localhost:7860`.\n",
    "  \n",
    "The `Flag` button can be used to *flag* outputs for manual review. The flagged outputs are stored within the `flagged`directory.\n",
    "\n",
    "You can find the full documentation for the Interface function [here](https://www.gradio.app/docs/gradio/interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23c94e-bf24-4d10-90b8-fcf2e2a7ddb4",
   "metadata": {},
   "source": [
    "# Components Overview\n",
    "Gradio offers a wide range of input and output [components](https://www.gradio.app/docs/gradio/components) to handle various data types and use cases. Here are some of the most commonly used components:\n",
    "\n",
    "- **Number**: Enables to enter a number. Useful to add additional information.\n",
    "- **Textbox**: Allows users to enter text. Useful for models that process text input like translations or sentiment analysis.\n",
    "- **Slider**: Provides a slider for numerical input. Ideal for parameters that range within a defined interval.\n",
    "- **Image**: Lets users upload an image or take a picture for image processing models.\n",
    "- **Dropdown**: Enables selection from a list of options. Perfect for choosing model options or categories.\n",
    "- **Label**: Displays text output. Commonly used to show the result from classification models.\n",
    "- **Image**: Allow for image handling. Useful for models that generate or modify images.\n",
    "- **JSON**: Handle JSON data. Ideal for displaying raw model outputs or more complex data structures.\n",
    "\n",
    "Each gradio application has a structure as shown in the image below([Source](https://raw.githubusercontent.com/gradio-app/gradio/main/guides/assets/dataflow.svg))\n",
    "![Data Flow of a gradio application](dataflow.svg)\n",
    "\n",
    "\n",
    "In addition, each component has its specific events that they support. We will investigate invents in a later lecture!\n",
    "\n",
    "Let's look at some examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e64e5-d671-4be8-8dd1-51edceacfa74",
   "metadata": {},
   "source": [
    "**Text Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc0592-0bc6-4c52-81d2-3074b17a97c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reverse_text(input_text):\n",
    "    return input_text[::-1]\n",
    "\n",
    "iface = gr.Interface(fn=reverse_text, inputs=gr.Text(), outputs=gr.Text())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c274ca7e-dae0-4f6a-beb8-b9e0429b7b2e",
   "metadata": {},
   "source": [
    "**Slider Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7f49e-4384-4410-948d-19996cc279f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slider_example(value):\n",
    "    return f\"Slider value: {value}\"\n",
    "\n",
    "iface = gr.Interface(fn=slider_example, inputs=gr.Slider(minimum=0, maximum=100), outputs=gr.Text())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04e826-1254-4fa8-af0b-0f4a59ccabd5",
   "metadata": {},
   "source": [
    "**Image Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfb71c-6699-4151-828d-0f7d12b53f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def to_grayscale(input_image):\n",
    "    grayscale_image = np.mean(input_image, axis=2, keepdims=True)\n",
    "    grayscale_image = np.tile(grayscale_image, (1, 1, 3))\n",
    "    return grayscale_image.astype(np.uint8)\n",
    "\n",
    "iface = gr.Interface(fn=to_grayscale, inputs=gr.Image(), outputs=gr.Image())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395285a-dc0f-401f-a705-047ee90bd29a",
   "metadata": {},
   "source": [
    "**Dropdown Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2064556-8169-4c09-ab9e-61d8ab7e54e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_dropdown(selection):\n",
    "    return f\"You selected: {selection}\"\n",
    "\n",
    "options = [\"Option 1\", \"Option 2\", \"Option 3\"]\n",
    "iface = gr.Interface(fn=handle_dropdown, inputs=gr.Dropdown(choices=options), outputs=gr.Text())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1d302-3fd0-441f-b3e9-8414c89a624e",
   "metadata": {},
   "source": [
    "**Json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe49061-2cde-4a98-936e-339f476b8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def number_details(number):\n",
    "    details = {\n",
    "        \"original\": number,\n",
    "        \"squared\": number ** 2,\n",
    "        \"sqrt\": number ** 0.5,\n",
    "        \"is_even\": number % 2 == 0\n",
    "    }\n",
    "    return details\n",
    "\n",
    "iface = gr.Interface(fn=number_details, inputs=gr.Number(), outputs=gr.Json())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a9e86-b04a-4622-b2ff-e797725c4bf4",
   "metadata": {},
   "source": [
    "**Label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb249a7-0d50-4cc8-b390-90b6d3c441d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_number(number):\n",
    "    if number > 0:\n",
    "        return \"Positive\"\n",
    "    elif number < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Zero\"\n",
    "\n",
    "iface = gr.Interface(fn=classify_number, inputs=gr.Number(), outputs=gr.Label())\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d006c3-e98b-4745-9b55-dd3a234ef0e2",
   "metadata": {},
   "source": [
    "Great! As we now are familiar with the basics of gradio we can take a look at more in-depth concepts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
