{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72566782-321f-4e1c-9ae4-8572b6fa99df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Audio Classification\n",
    "\n",
    "# Libraries\n",
    "\n",
    "Balancing, torch, torchaudio, and transformers can be tricky! Here are the versions used for this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531a21a-2753-4230-94f1-4c4c3b11bb85",
   "metadata": {},
   "source": [
    "## Library and Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458a072c-f306-49c7-9af4-675a1850fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the versions used for this notebook, but watch the lecture for an important note on this\n",
      "2.3.0+cpu\n",
      "2.3.0+cpu\n",
      "4.44.2\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, torchaudio\n",
    "print(\"These are the versions used for this notebook, but watch the lecture for an important note on this\")\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe422402-cac1-4962-9d91-be9af4b7e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d0307d-bb51-40fe-bf3a-bb99501aff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06e7008-d918-4f2a-84f1-ed9700d00e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_path = 'example.mp3'\n",
    "y, sr = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee2059-3f2b-4273-8f84-e4bcaae2419d",
   "metadata": {},
   "source": [
    "## Sampling Rate Issues\n",
    "\n",
    "Recall that most ML models are trained on 16 kHz sampling rate, you will run into issues if you try to force your own sampling rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8caf3d-0511-457f-a1a3-377921e358a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR!\n",
    "\n",
    "# You can leave the sampling_rate column if your sampling rate doesnt match 16000,\n",
    "# the model will automatically upsample / downsample to 16000 Hz\n",
    "\n",
    "# result = feature_extractor(y,sampling_rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87cec69-240e-44d9-897b-f7ae5c08b052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "result = feature_extractor(y,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728a1b1f-61fc-4111-afc5-bb186e706b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[[ 0.0770, -0.2676,  0.1092,  ..., -1.2776, -1.2776, -1.2776],\n",
       "         [ 0.0846, -0.2771,  0.0997,  ..., -1.2776, -1.2776, -1.2776],\n",
       "         [-0.2939, -0.3674,  0.0095,  ..., -1.2776, -1.2776, -1.2776],\n",
       "         ...,\n",
       "         [ 0.2184, -0.0845,  0.2923,  ..., -1.2776, -1.2776, -1.2776],\n",
       "         [ 0.1963, -0.1293,  0.2475,  ..., -1.2776, -1.2776, -1.2776],\n",
       "         [-0.0509, -0.4521, -0.0752,  ..., -1.2776, -1.2776, -1.2776]]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae49bafd-8bb0-408b-b5bf-1ed7d4e254aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4efed1-1818-403b-b32d-5653d84b5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logits = model(result['input_values']).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98da0a86-5902-49a3-b062-de29467861dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.9081,  -9.2253,  -9.4442,  -9.4990, -10.3686,  -9.8169, -10.5372,\n",
       "          -9.9140, -11.0119, -11.1294, -10.8732, -11.3651, -12.3890, -11.9322,\n",
       "         -10.1947, -10.5203, -10.9214, -11.4615, -11.2874, -10.9701, -11.3812,\n",
       "         -11.1792, -10.5879, -10.7083,  -9.4158, -11.2141, -10.9959,  -8.1345,\n",
       "          -8.3063, -12.1890,  -8.9141,  -8.1373,  -9.5586, -10.1567, -10.2660,\n",
       "         -11.6801, -10.3482, -10.8475, -10.4001, -10.8535, -11.0698,  -9.5788,\n",
       "         -12.0086, -10.2645, -10.1869, -10.8037, -10.6147, -10.8702, -11.1634,\n",
       "         -11.6032, -12.3197, -11.4073, -10.7273, -10.6266, -10.7189, -10.2814,\n",
       "         -12.3984, -10.6907, -11.4477, -10.8105, -12.4599, -10.8371, -11.6523,\n",
       "         -11.1757,  -8.7801,  -9.1707, -11.2029, -10.2863, -11.8267,  -9.5817,\n",
       "         -10.8891, -11.8293,  -7.8608,  -8.4752,  -9.2617, -10.5787, -10.6426,\n",
       "         -10.5211,  -9.6369, -11.0325,  -9.8193,  -9.8407, -11.3109, -10.0103,\n",
       "          -9.1413, -11.3183,  -9.6363, -10.5181, -10.5326, -12.0045,  -9.7329,\n",
       "         -10.8257, -11.1573, -10.9969, -10.1537, -11.7148, -10.4393, -10.0457,\n",
       "          -9.5154, -10.3393, -11.1337, -11.2132, -10.6031, -10.6171,  -9.9654,\n",
       "         -10.8855, -10.8607, -10.2859, -10.3977, -10.0613, -10.8958,  -8.9154,\n",
       "         -10.0099, -11.0398, -11.1266, -10.3692, -10.9305, -10.7355, -10.7680,\n",
       "         -10.6131, -11.3413, -11.0807, -10.5832, -11.4765, -11.0102, -11.1487,\n",
       "          -9.4741, -11.3131, -11.3831, -10.1499,  -8.8026,  -9.8782, -10.2924,\n",
       "         -11.2721, -10.7637, -10.0475,  -9.4250,   0.4300,  -1.4319,  -6.8755,\n",
       "          -6.6131,  -8.5558,  -8.5463,  -7.5936, -10.0831, -10.4967,  -8.0951,\n",
       "         -10.5235, -10.2498,  -8.7156,  -8.7834, -10.2167,  -5.4794,  -4.7773,\n",
       "          -8.1011,  -6.5816,  -8.6970,  -7.7294,  -7.4143,  -8.5919,  -6.7687,\n",
       "          -7.3252,  -7.8707, -10.0673,  -7.6365,  -9.8580,  -9.6902, -10.7651,\n",
       "          -9.0910,  -5.2914, -10.8723,  -9.9249, -10.1679, -10.1487, -11.4788,\n",
       "         -11.7280, -12.4099,  -7.3504,  -9.1572,  -9.2087,  -8.5854,  -8.9355,\n",
       "          -9.1996, -10.8581,  -1.8113,  -6.1373,  -6.0532,  -7.5425,  -6.8150,\n",
       "          -0.6655,  -1.8169,  -1.4128,  -5.8041,   0.2643,  -1.2275,  -7.2777,\n",
       "          -7.7061,  -8.2559,  -8.2045,  -8.4547,  -7.9105,  -8.4694,  -9.8173,\n",
       "         -12.0253, -10.9005, -10.6103, -11.9745,  -9.4159,  -9.0896,  -8.8592,\n",
       "          -9.5125,  -8.1735, -10.2054,  -7.6791,  -8.1452, -10.6568,  -9.0703,\n",
       "          -9.3680, -11.0343,  -9.0656,  -8.3357,  -9.1140,  -9.4543,  -9.1140,\n",
       "          -8.8625,  -9.4616,  -8.1090,  -8.2514, -11.0697,  -7.6292,  -9.9742,\n",
       "          -8.8073,  -9.2797,  -7.9875,  -7.9516,  -7.4070, -10.1921,  -1.9498,\n",
       "          -6.1480,  -6.6403,  -9.2608,  -8.2486,  -8.2451,  -9.9719,  -8.3496,\n",
       "          -9.3053,  -6.4909,  -8.6586,  -9.4429, -11.3152,  -8.1062,  -8.0532,\n",
       "          -9.8256,  -7.0520,  -9.9942, -10.9314, -10.3782, -10.9846,  -8.1131,\n",
       "          -9.3158,  -9.2393,  -9.0825, -11.2661, -10.4387,  -7.9818,  -7.6349,\n",
       "          -9.6584,  -4.9590,  -4.2996,  -9.2699,  -4.3060,  -7.6594,  -6.6592,\n",
       "          -8.0987,  -9.0688,  -5.8876,  -8.4456,  -8.3315,  -4.3573,  -5.8473,\n",
       "          -6.6354,  -8.5419,  -3.6140,  -9.8581,  -9.6094,  -9.6057, -10.2131,\n",
       "         -10.0596,  -9.7069,  -9.9575, -10.3185,  -9.9919, -10.0574, -10.4357,\n",
       "          -9.9153, -10.0350, -10.4551, -10.0486, -10.9560, -11.2392,  -6.1035,\n",
       "          -8.3096,  -9.8094, -10.6017,  -9.4351,  -9.3881,  -8.8800,  -7.3255,\n",
       "          -9.5954, -10.0896, -11.8437, -11.9944, -11.1438, -11.3778,  -9.4987,\n",
       "         -10.0680,  -9.5604, -10.9194, -10.8022, -10.8105, -11.7541,  -8.4908,\n",
       "         -10.3638, -10.6319, -11.1494, -10.3253,  -9.7755,  -9.7374,  -8.4655,\n",
       "          -8.2878, -11.1102,  -9.7361,  -8.3484, -10.6815, -10.0333,  -8.7086,\n",
       "          -9.7731, -10.5014,  -9.5137, -10.5344,  -8.6966, -10.2862, -11.9116,\n",
       "          -8.8287, -10.7487, -10.9666, -10.5173, -11.3691,  -9.9821,  -9.7356,\n",
       "         -10.7288, -10.8355,  -9.8492,  -9.3838, -10.5110, -11.7532, -10.4866,\n",
       "         -11.1524, -10.6830, -11.6753,  -9.2969, -11.2406, -10.9046, -12.9853,\n",
       "         -10.7980, -12.0079, -11.0965, -11.2718,  -8.5802, -11.3292, -11.1634,\n",
       "         -11.5378, -10.6431, -10.9956, -11.7193, -11.3479, -11.7661, -11.1956,\n",
       "         -10.2958, -10.9797, -11.4412, -12.1931, -11.3892, -11.9881, -10.2856,\n",
       "         -11.5581,  -9.8520,  -9.9037, -10.8921, -10.9863, -11.2686, -10.0095,\n",
       "         -11.4514, -10.3062, -10.2749, -10.9382,  -9.3200,  -9.6347, -11.1500,\n",
       "         -11.2691, -11.3676,  -7.6472, -11.2387, -11.3087,  -9.0157, -10.5773,\n",
       "         -11.0836,  -9.8965,  -9.5430, -10.5482, -12.2448, -10.7935, -10.5800,\n",
       "          -9.7354, -11.6099,  -9.8166, -11.4525, -10.3505,  -9.7880,  -9.6779,\n",
       "         -11.3579, -11.7079, -11.6343, -11.8440, -10.5128, -11.4875,  -9.7587,\n",
       "          -8.7508, -10.0785, -10.9720,  -9.8802, -11.5815, -11.2129, -11.5732,\n",
       "          -8.9675, -10.0057, -10.0783, -10.0697, -11.3742, -13.4724, -12.2799,\n",
       "          -9.9220, -10.2079, -10.7791, -10.3969, -12.2077, -11.6577, -10.6070,\n",
       "         -11.1305, -11.1907, -11.2188, -10.7186, -11.0600,  -9.8152, -11.9005,\n",
       "         -12.3758, -11.8247,  -8.5626, -11.5660,  -8.5471,  -9.4409,  -9.7390,\n",
       "          -9.8128,  -9.8606, -10.2806, -11.4655,  -9.1085, -10.7802,  -9.9842,\n",
       "         -10.8448, -10.4663, -10.6041, -11.9202,  -9.8174, -12.0070, -11.2889,\n",
       "         -10.8205,  -9.5464, -11.4868, -12.3960, -11.6334,  -9.4803,  -9.7509,\n",
       "          -9.8122, -11.0075, -12.3329, -12.5127,  -9.1825, -10.2188,  -9.4983,\n",
       "         -11.3232, -10.9226, -10.5472,  -6.2590, -11.8984,  -9.9241,  -8.3434,\n",
       "          -9.9370, -12.2206, -10.4559,  -7.5244,  -9.7453,  -7.5909, -10.0599,\n",
       "          -7.2087,  -9.3882,  -6.8283,  -6.1235,  -8.0279,  -7.0175,  -6.9616,\n",
       "          -8.9820,  -7.8229, -11.0230, -11.1495, -10.1394,  -9.0847, -10.3326,\n",
       "         -10.7166,  -9.7585,  -8.9684, -10.1934,  -8.1415,  -9.4875,  -8.7257,\n",
       "         -10.2586,  -8.4603]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3dfc19c-b0ab-4b67-95c5-ee9df7361908",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_ids = torch.argmax(prediction_logits, dim=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e792e681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c23e65a9-6d79-4e3c-88ed-d425f0b835f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = model.config.id2label[predicted_class_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a86578c-bba3-48b3-be8d-e28aa5a17776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Music'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f843c03b-cf0c-4922-98bb-dbe07d5af1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe6d98-87b8-4086-95c1-d96bf40536d8",
   "metadata": {},
   "source": [
    "## Pipeline for Audio Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7bb1d37-859f-4cee-8979-aea1ab77038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"audio-classification\", model=\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d725f7ef-cc90-433d-b5da-af0b141a9cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTForAudioClassification(\n",
       "  (audio_spectrogram_transformer): ASTModel(\n",
       "    (embeddings): ASTEmbeddings(\n",
       "      (patch_embeddings): ASTPatchEmbeddings(\n",
       "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ASTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ASTLayer(\n",
       "          (attention): ASTSdpaAttention(\n",
       "            (attention): ASTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ASTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ASTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ASTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): ASTMLPHead(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "160631d9-bcc8-4771-a43b-56cbd6d428a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Gen_AI_Automation_Deep_Learning\\Hugging_Face_Course\\venv\\Lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\feature_extraction_audio_spectrogram_transformer.py:118: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  waveform = torch.from_numpy(waveform).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.48486775159835815, 'label': 'Music'},\n",
       " {'score': 0.1913110315799713, 'label': 'Violin, fiddle'},\n",
       " {'score': 0.08519726246595383, 'label': 'Musical instrument'},\n",
       " {'score': 0.04692425578832626, 'label': 'Bowed string instrument'},\n",
       " {'score': 0.04536106064915657, 'label': 'Orchestra'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('example.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d3ea93-a1b1-4272-b42d-87a04964f0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipe.model.config.id2label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
