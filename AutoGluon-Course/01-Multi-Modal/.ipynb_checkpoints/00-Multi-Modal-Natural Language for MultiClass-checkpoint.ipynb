{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5953c1c",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/meetnagadia/amazon-kindle-book-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c402d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ba6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TabularDataset(\"data/kindle_review/review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df973025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler      1356912000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96158c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.8)\n",
    "seed = 42\n",
    "train_data = data.sample(train_size, random_state=seed)\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73773de1",
   "metadata": {},
   "source": [
    "## Feature Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480a718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import FeatureMetadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureMetadata.from_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0797e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('int', [])                        : 4 | ['Unnamed: 0.1', 'Unnamed: 0', 'rating', 'unixReviewTime']\n",
      "('object', [])                     : 4 | ['asin', 'helpful', 'reviewerID', 'reviewerName']\n",
      "('object', ['datetime_as_object']) : 1 | ['reviewTime']\n",
      "('object', ['text'])               : 1 | ['reviewText']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea77727",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'book_rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008a63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label=\"rating\", path=save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-marshall",
   "metadata": {},
   "source": [
    "Let's pass **multimodal** to the *hyperparameters* argument to tell autogluon that we want it to use its multimodal tuning procedure.\n",
    "This additionally trains a Transformer Network.\n",
    "\n",
    "Note that you need to have at least one nvidia GPU to be able to train a transformer in autogluon.\n",
    "Otherwise just remove the multimodal parameter and we train autogluon as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22644acb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"sentiment_analysis/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.0\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #64~20.04.1-Ubuntu SMP Fri Jan 6 16:42:31 UTC 2023\n",
      "Train Data Rows:    9600\n",
      "Train Data Columns: 9\n",
      "Label Column: rating\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t5 unique label values:  [3, 1, 2, 4, 5]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    54221.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tFitting RenameFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['reviewText']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6657\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])                        : 3 | ['Unnamed: 0.1', 'Unnamed: 0', 'unixReviewTime']\n",
      "\t\t('object', [])                     : 4 | ['asin', 'helpful', 'reviewerID', 'reviewerName']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['reviewTime']\n",
      "\t\t('object', ['text'])               : 1 | ['reviewText']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    4 | ['asin', 'helpful', 'reviewerID', 'reviewerName']\n",
      "\t\t('int', [])                         :    3 | ['Unnamed: 0.1', 'Unnamed: 0', 'unixReviewTime']\n",
      "\t\t('int', ['binned', 'text_special']) :   32 | ['reviewText.char_count', 'reviewText.word_count', 'reviewText.capital_ratio', 'reviewText.lower_ratio', 'reviewText.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :    5 | ['reviewTime', 'reviewTime.year', 'reviewTime.month', 'reviewTime.day', 'reviewTime.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 6658 | ['__nlp__.000', '__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.14', ...]\n",
      "\t\t('object', ['text'])                :    1 | ['reviewText_raw_text']\n",
      "\t9.8s = Fit runtime\n",
      "\t9 features in original data used to generate 6703 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 135.44 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8640, Val Rows: 960\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6177\t = Validation score   (accuracy)\n",
      "\t20.21s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6281\t = Validation score   (accuracy)\n",
      "\t9.39s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (6702), dynamically setting 'colsample_bylevel' to 0.14920919128618323 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.624\t = Validation score   (accuracy)\n",
      "\t37.47s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6302\t = Validation score   (accuracy)\n",
      "\t60.35s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5188\t = Validation score   (accuracy)\n",
      "\t13.84s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit ...\n",
      "\tWarning: Exception caused VowpalWabbit to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.5\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6354\t = Validation score   (accuracy)\n",
      "\t49.77s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor ...\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8be4f6ab78b46de98eac91e1db98ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089c92ee95b341739f5a13cf768e1e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725669b5248545c5af26692b846de544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5342747f76584783a22427aafec95568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495ed44bced2412993b375c0c98a638f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 109 M \n",
      "1 | validation_metric | Accuracy            | 0     \n",
      "2 | loss_func         | CrossEntropyLoss    | 0     \n",
      "----------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "219.575   Total estimated model params size (MB)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 33: 'val_accuracy' reached 0.46458 (best 0.46458), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=0-step=33.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 68: 'val_accuracy' reached 0.58021 (best 0.58021), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=0-step=68.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 101: 'val_accuracy' reached 0.63646 (best 0.63646), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=1-step=101.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 136: 'val_accuracy' reached 0.65312 (best 0.65312), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=1-step=136.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 169: 'val_accuracy' reached 0.66667 (best 0.66667), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=2-step=169.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 204: 'val_accuracy' reached 0.64896 (best 0.66667), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=2-step=204.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 237: 'val_accuracy' reached 0.66250 (best 0.66667), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=3-step=237.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 272: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 305: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 340: 'val_accuracy' reached 0.66146 (best 0.66667), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/epoch=4-step=340.ckpt' as top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 373: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 408: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 441: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 476: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 509: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Configuration saved in sentiment_analysis/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
      "tokenizer config file saved in sentiment_analysis/models/MultiModalPredictor/automm_model/hf_text/tokenizer_config.json\n",
      "Special tokens file saved in sentiment_analysis/models/MultiModalPredictor/automm_model/hf_text/special_tokens_map.json\n",
      "\t0.6781\t = Validation score   (accuracy)\n",
      "\t847.47s\t = Training   runtime\n",
      "\t5.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7219\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1059.09s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"sentiment_analysis/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f282484a4c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_data, hyperparameters=\"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "equivalent-malta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28e48b",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351f37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[\"rating\"]\n",
    "test_data = test_data.drop(columns=[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef2962f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/hf_text\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Load pretrained checkpoint: /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/sentiment_analysis/models/MultiModalPredictor/automm_model/model.ckpt\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2647b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.6991666666666667\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.6991666666666667,\n",
      "    \"balanced_accuracy\": 0.6860845394801982,\n",
      "    \"mcc\": 0.6196219412976858\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "metrics = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2af6e6",
   "metadata": {},
   "source": [
    "We can use sklearn to obtain more in-depth metrics like a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "791fcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee03eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287,  76,  32,   5,   8],\n",
       "       [ 64, 223,  79,   8,   8],\n",
       "       [  5,  16, 270, 108,  25],\n",
       "       [  0,   1,  50, 367, 154],\n",
       "       [  0,   0,   2,  81, 531]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965b1f9",
   "metadata": {},
   "source": [
    "We can see that the model mainly struggeled to differentiate between 3 and 4 as well as 4 and 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-share",
   "metadata": {},
   "source": [
    "# MultiModalPredictor\n",
    "Instead of using the TabularPredictor and pass multimodal as a hyperparameter we can directly use the MultiModalPredictor. However, if the dataset contains many numerical columns, TabularPredictor will usually perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "binary-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compact-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=\"transformer_book_rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "catholic-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(label=\"rating\", path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-project",
   "metadata": {},
   "source": [
    "When training the model you can see that the pytorch model parameters are similar to above.\n",
    "However, no additional model is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mexican-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Global seed set to 123\n",
      "AutoMM starts to create your model. ✨\n",
      "\n",
      "- Model will be saved to \"/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating\".\n",
      "\n",
      "- Validation metric is \"accuracy\".\n",
      "\n",
      "- To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating\n",
      "    ```\n",
      "\n",
      "Enjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n",
      "\n",
      "loading configuration file config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/pytorch_model.bin\n",
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at google/electra-base-discriminator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/marci/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Configuration saved in /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/hf_text/config.json\n",
      "tokenizer config file saved in /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/hf_text/tokenizer_config.json\n",
      "Special tokens file saved in /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/hf_text/special_tokens_map.json\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 109 M \n",
      "1 | validation_metric | Accuracy            | 0     \n",
      "2 | loss_func         | CrossEntropyLoss    | 0     \n",
      "----------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "219.574   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c8d7a8f8084901a1ae2496bfa690ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b53d73bda640689e070df23a64ec00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442160a56d044edea3d643535a7546a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 33: 'val_accuracy' reached 0.42500 (best 0.42500), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=0-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0faff30c0434e268371f6d41f986334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 68: 'val_accuracy' reached 0.60938 (best 0.60938), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=0-step=68.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ff7d70be2a47c7b420d340c7323da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 101: 'val_accuracy' reached 0.58021 (best 0.60938), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=1-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40644a68f56745e785857d068fa8c68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 136: 'val_accuracy' reached 0.62083 (best 0.62083), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=1-step=136.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085df7be45d64d3285267f274f725396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 169: 'val_accuracy' reached 0.65000 (best 0.65000), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=2-step=169.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaaf611e7224c08b23eff943b049cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 204: 'val_accuracy' reached 0.64375 (best 0.65000), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=2-step=204.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dba7b1a64d34bcb80510887faf4690f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 237: 'val_accuracy' reached 0.62292 (best 0.65000), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=3-step=237.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7968f4aa9e4673ae92a45b14f699c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 272: 'val_accuracy' reached 0.66562 (best 0.66562), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=3-step=272.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecaf240fda524859bc54425b5e5bb274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 305: 'val_accuracy' reached 0.66979 (best 0.66979), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=4-step=305.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d782f91b04067ac41f832a49090dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 340: 'val_accuracy' reached 0.65417 (best 0.66979), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=4-step=340.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac6725cf1ac449d91e39b0963f70ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 373: 'val_accuracy' reached 0.65521 (best 0.66979), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=5-step=373.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d4934da04e4d2985855c907c0f69a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 408: 'val_accuracy' reached 0.66458 (best 0.66979), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=5-step=408.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae302e01cad944cc8e9c84b51f3fc462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 441: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d72dac4ea8e45f1b3c03e25938fb8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 476: 'val_accuracy' reached 0.66771 (best 0.66979), saving model to '/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating/epoch=6-step=476.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079a79ebdea4430c8539c6cff6fea3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 509: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9812a0bcf7468ca5d0f3fc9a668733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 544: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10ebf27b5744715bb70d3da25ba3535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 577: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5133c91f028c4cbc961854174a48ad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 612: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a3172fe0e743c0ae4ebc4a2b0e3d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 645: 'val_accuracy' was not in top 3\n",
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca72995c2d104e53a9240dc2ea8ec743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaa9c19abbb4fe29d725e4f963a8d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cedce643a6244a0bd4dfaa857b95bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model 🎉🎉🎉\n",
      "\n",
      "- To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating\")\n",
      "    ```\n",
      "\n",
      "- You can open a terminal and launch Tensorboard to visualize the training log:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/marci/GIT/AutoGluon-Course/01-Multi-Modal/transformer_book_rating\n",
      "    ```\n",
      "\n",
      "- If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub: https://github.com/autogluon/autogluon\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x7f2888d27970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-checkout",
   "metadata": {},
   "source": [
    "Note that MultiModalPredictor has no evalute_predictions functions.\n",
    "Only *evaluate* is implemented which requires a dataset that also includes the label - so let us create this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "assisted-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_new = test_data\n",
    "test_data_new[\"rating\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "reliable-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100872fb710f49aeb459215a5a491f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6625}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-blanket",
   "metadata": {},
   "source": [
    "Note that the accuracy dropped in comparison to above as only the Transformer was used and not an Ensemble!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-origin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
